<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article" xml:lang="en"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">J Cheminform</journal-id><journal-id journal-id-type="iso-abbrev">J Cheminform</journal-id><journal-title-group><journal-title>Journal of Cheminformatics</journal-title></journal-title-group><issn pub-type="epub">1758-2946</issn><publisher><publisher-name>BioMed Central</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">25810774</article-id><article-id pub-id-type="pmc">4331693</article-id><article-id pub-id-type="publisher-id">1758-2946-7-S1-S3</article-id><article-id pub-id-type="doi">10.1186/1758-2946-7-S1-S3</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research</subject></subj-group></article-categories><title-group><article-title>tmChem: a high performance approach for chemical named entity recognition and normalization</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes" id="A1"><name><surname>Leaman</surname><given-names>Robert</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>robert.leaman@nih.gov</email></contrib><contrib contrib-type="author" equal-contrib="yes" id="A2"><name><surname>Wei</surname><given-names>Chih-Hsuan</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>chih-hsuan.wei@nih.gov</email></contrib><contrib contrib-type="author" corresp="yes" id="A3"><name><surname>Lu</surname><given-names>Zhiyong</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>zhiyong.lu@nih.gov</email></contrib></contrib-group><aff id="I1"><label>1</label>National Center for Biotechnology Information, 8600 Rockville Pike, Bethesda, Maryland 20894, USA</aff><pub-date pub-type="collection"><year>2015</year></pub-date><pub-date pub-type="epub"><day>19</day><month>1</month><year>2015</year></pub-date><volume>7</volume><issue>Suppl 1</issue><supplement><named-content content-type="supplement-title">Text mining for chemistry and the CHEMDNER track</named-content></supplement><fpage>S3</fpage><lpage>S3</lpage><permissions><copyright-statement>Copyright &#x000a9; 2015 Leaman et al.; licensee Springer.</copyright-statement><copyright-year>2015</copyright-year><copyright-holder>Leaman et al.; licensee Springer.</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0"><license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0">http://creativecommons.org/licenses/by/4.0</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p></license></permissions><self-uri xlink:href="http://www.jcheminf.com/content/7/S1/S3"/><abstract><p>Chemical compounds and drugs are an important class of entities in biomedical research with great potential in a wide range of applications, including clinical medicine. Locating chemical named entities in the literature is a useful step in chemical text mining pipelines for identifying the chemical mentions, their properties, and their relationships as discussed in the literature.</p><p>We introduce the tmChem system, a chemical named entity recognizer created by combining two independent machine learning models in an ensemble. We use the corpus released as part of the recent CHEMDNER task to develop and evaluate tmChem, achieving a micro-averaged f-measure of 0.8739 on the CEM subtask (mention-level evaluation) and 0.8745 f-measure on the CDI subtask (abstract-level evaluation). We also report a high-recall combination (0.9212 for CEM and 0.9224 for CDI). tmChem achieved the highest f-measure reported in the CHEMDNER task for the CEM subtask, and the high recall variant achieved the highest recall on both the CEM and CDI tasks.</p><p>We report that tmChem is a state-of-the-art tool for chemical named entity recognition and that performance for chemical named entity recognition has now tied (or exceeded) the performance previously reported for genes and diseases. Future research should focus on tighter integration between the named entity recognition and normalization steps for improved performance.</p><p>The source code and a trained model for both models of tmChem is available at: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/tmChem">http://www.ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/tmChem</ext-link>. The results of running tmChem (Model 2) on PubMed are available in PubTator: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/PubTator">http://www.ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/PubTator</ext-link></p></abstract></article-meta></front><body><sec><title>Background</title><p>The effects of chemicals on living systems of every scale make them an exceptionally important class of entities for biomedical research and clinical applications. These effects may be therapeutic (as in drugs), investigational (as in drug discovery) or unintentional (as in adverse effects or environmental toxicities) [<xref ref-type="bibr" rid="B1">1</xref>]. As such, chemicals/drugs are one of the topics most frequently searched in PubMed [<xref ref-type="bibr" rid="B2">2</xref>,<xref ref-type="bibr" rid="B3">3</xref>]. While extracting chemical mentions from biomedical literature has been attempted previously [<xref ref-type="bibr" rid="B4">4</xref>], the task has not yet yielded results approaching those of better-studied entity types such as genes/proteins [<xref ref-type="bibr" rid="B5">5</xref>-<xref ref-type="bibr" rid="B7">7</xref>], species [<xref ref-type="bibr" rid="B8">8</xref>], and diseases [<xref ref-type="bibr" rid="B9">9</xref>]. This is likely due in part to both the great variety of biologically relevant chemical structures and to the somewhat different properties exhibited by chemical mentions. These properties include systematic and semi-systematic methods for describing chemical structure (e.g. formulas and IUPAC names), whose highly compositional nature makes it difficult to precisely determine the entity boundaries, or even the number of entities present.</p><sec><title>Related work</title><p>Recent reviews detail the considerable previous work on chemical text mining from the biomedical or chemical literature, concentrating primarily on chemical named entity recognition [<xref ref-type="bibr" rid="B10">10</xref>,<xref ref-type="bibr" rid="B11">11</xref>]. Many of these previous systems focus effort on a specific area of interest. For example, the Jochem dictionary uses a lexical approach to identify drugs and other small molecules named in biomedical text [<xref ref-type="bibr" rid="B12">12</xref>], while Klinger, et al. [<xref ref-type="bibr" rid="B13">13</xref>] use a machine learning approach with conditional random fields (CRF) to find chemicals mentioned using the IUPAC systematic format, reporting an f-measure of 0.815.</p><p>Systems with a broader focus have also been developed. The OSCAR system employs a hybrid approach for chemical text mining in chemistry publications [<xref ref-type="bibr" rid="B14">14</xref>]. Rocktaschel, et al. [<xref ref-type="bibr" rid="B4">4</xref>] use a lexical approach to locate trivial names, abbreviations and drugs, and also employ a conditional random field method to locate IUPAC names to create a hybrid chemical named entity recognition tool called ChemSpot, reporting an f-measure of 0.681 on the SCAI corpus.</p><p>There has also been increasing interest in the creation of annotated corpora to assist in system development and evaluation. Kolarik, et al. [<xref ref-type="bibr" rid="B15">15</xref>] survey available chemical resources and also report the creation of the SCAI corpus with chemical mention annotations. In addition, the CALBC Silver Standard corpus - created by pooling the output of multiple systems - includes one mention type which combines chemicals and drugs [<xref ref-type="bibr" rid="B16">16</xref>,<xref ref-type="bibr" rid="B17">17</xref>].</p><p>The most recent effort to create annotated corpora to support chemical named entity recognition was the CHEMDNER task at BioCreative IV, which attracted 27 participating teams [<xref ref-type="bibr" rid="B18">18</xref>]. This paper describes the creation of the tmChem system, our submissions to the CHEMDNER task [<xref ref-type="bibr" rid="B19">19</xref>], and subsequent experiments and analysis. One of our submissions achieved the highest f-measure reported for the CEM subtask, and our high recall variant achieved the highest recall reported in both the CDI and CEM subtasks.</p></sec></sec><sec sec-type="methods"><title>Methods</title><sec><title>CHEMDNER dataset</title><p>The CHEMDNER Corpus consists of 10,000 abstracts published in 2013 in top journals from chemistry-related disciplines [<xref ref-type="bibr" rid="B18">18</xref>]. Each abstract selected was human annotated for all chemical mentions sufficiently specific to be able to be associated with chemical structure information. Nearly all mentions were assigned one of seven different subtypes (ABBREVIATION, FAMILY, FORMULA, IDENTIFIER, MULTIPLE, SYSTEMATIC, and TRIVIAL) as illustrated in Figure <xref ref-type="fig" rid="F1">1</xref>. The corpus is divided into Training (3,500 abstracts), Development (3,500 abstracts) and Test (3,000 abstracts) sets. The full CHEMDNER corpus and the complete annotation guidelines are available for download (after free registration) [<xref ref-type="bibr" rid="B20">20</xref>].</p><fig id="F1" position="float"><label>Figure 1</label><caption><p><bold>Sample sentence from the CHEMDNER Corpus with illustrative chemical entity annotations of types SYSTEMATIC, ABBREVIATION, TRIVIAL and FORMULA</bold>.</p></caption><graphic xlink:href="1758-2946-7-S1-S3-1"/></fig><p>The CHEMDNER Corpus was prepared for the recent CHEMDNER task at BioCreative IV [<xref ref-type="bibr" rid="B18">18</xref>]. This task was separated into two sub-tasks, the CEM (Chemical Entity Mention) subtask, which evaluates performance at the mention level, and also the CDI (Chemical Document Indexing) subtask, which evaluates performance at the abstract level.</p></sec><sec><title>System description</title><p>Many successful named entity recognition systems have improved performance by exploiting the complementary strengths of multiple models [<xref ref-type="bibr" rid="B5">5</xref>]. This approach is an instance of the machine learning method of ensemble learning, and requires sufficient differences between the systems combined [<xref ref-type="bibr" rid="B21">21</xref>]. Here we combine two linear chain conditional random fields (CRF) models employing different tokenizations and feature sets. These models were prepared by independently adapting existing named entity recognition systems, in an attempt to take advantage of the performance improvements of ensemble learning. Model 1 is an adaptation of the BANNER named entity recognizer to chemicals [<xref ref-type="bibr" rid="B22">22</xref>]. Model 2 was created using CRF++ [<xref ref-type="bibr" rid="B23">23</xref>] by repurposing part of the tmVar system for locating genetic variants [<xref ref-type="bibr" rid="B24">24</xref>]. Both models also employ multiple post processing steps. We then use several strategies to combine the output of the two models for improved performance. The differences between the models are summarized in Table <xref ref-type="table" rid="T1">1</xref> and described in detail in the following sections.</p><table-wrap id="T1" position="float"><label>Table 1</label><caption><p>Comparison of Model 1 and Model 2.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Aspect</th><th align="left">Model 1</th><th align="left">Model 2</th></tr></thead><tbody><tr><td align="left">System adapted</td><td align="left">BANNER [<xref ref-type="bibr" rid="B22">22</xref>]</td><td align="left">tmVar [<xref ref-type="bibr" rid="B24">24</xref>]</td></tr><tr><td colspan="3"><hr/></td></tr><tr><td align="left" colspan="3"><bold>Preprocessing</bold></td></tr><tr><td colspan="3"><hr/></td></tr><tr><td align="left">Unicode transliteration</td><td align="left">No</td><td align="left">Yes</td></tr><tr><td colspan="3"><hr/></td></tr><tr><td align="left">Tokenization</td><td align="left">whitespace<break/>punctuation<break/>digits<break/>lowercase to uppercase</td><td align="left">whitespace<break/>punctuation<break/>digits<break/>lowercase to uppercase<break/>uppercase to lowercase</td></tr><tr><td colspan="3"><hr/></td></tr><tr><td align="left">Sentence segmentation</td><td align="left">Java BreakIterator</td><td align="left">None</td></tr><tr><td colspan="3"><hr/></td></tr><tr><td align="left" colspan="3"><bold>Conditional random field configuration and settings</bold></td></tr><tr><td colspan="3"><hr/></td></tr><tr><td align="left">Implementation</td><td align="left">MALLET [<xref ref-type="bibr" rid="B25">25</xref>]</td><td align="left">CRF++ [<xref ref-type="bibr" rid="B23">23</xref>]</td></tr><tr><td colspan="3"><hr/></td></tr><tr><td align="left">Order</td><td align="left">1</td><td align="left">2</td></tr><tr><td colspan="3"><hr/></td></tr><tr><td align="left">Label model</td><td align="left">IOB with one entity label</td><td align="left">IOB with one entity label</td></tr><tr><td colspan="3"><hr/></td></tr><tr><td align="left">Regularization</td><td align="left">L<sub>2</sub></td><td align="left">L<sub>2</sub></td></tr><tr><td colspan="3"><hr/></td></tr><tr><td align="left">Gaussian prior variance (&#x003c3;)</td><td align="left">1.0</td><td align="left">4.0</td></tr><tr><td colspan="3"><hr/></td></tr><tr><td align="left">Feature frequency threshold</td><td align="left">0</td><td align="left">3</td></tr><tr><td colspan="3"><hr/></td></tr><tr><td align="left" colspan="3"><bold>Features</bold></td></tr><tr><td colspan="3"><hr/></td></tr><tr><td align="left">Individual tokens</td><td align="left">Yes</td><td align="left">Yes</td></tr><tr><td colspan="3"><hr/></td></tr><tr><td align="left">Morphology</td><td align="left">Lemmatization</td><td align="left">Stemming</td></tr><tr><td colspan="3"><hr/></td></tr><tr><td align="left">Part of speech</td><td align="left">Yes</td><td align="left">No</td></tr><tr><td colspan="3"><hr/></td></tr><tr><td align="left">Word shapes</td><td align="left">Yes</td><td align="left">Yes</td></tr><tr><td colspan="3"><hr/></td></tr><tr><td align="left">Characters</td><td align="left">N-grams length 2 - 4</td><td align="left">Prefixes and suffixes length 2 - 5</td></tr><tr><td colspan="3"><hr/></td></tr><tr><td align="left">Character counts</td><td align="left">None</td><td align="left">Total characters, digits, uppercase, lowercase</td></tr><tr><td colspan="3"><hr/></td></tr><tr><td align="left">ChemSpot [<xref ref-type="bibr" rid="B4">4</xref>]</td><td align="left">Yes</td><td align="left">No</td></tr><tr><td colspan="3"><hr/></td></tr><tr><td align="left">Semantic affixes</td><td align="left">None</td><td align="left">Suffixes, alkane stems, trivial rings, simple multipliers, etc.</td></tr><tr><td colspan="3"><hr/></td></tr><tr><td align="left">Chemical elements</td><td align="left">Name and symbol</td><td align="left">Name</td></tr><tr><td colspan="3"><hr/></td></tr><tr><td align="left">Amino acids</td><td align="left">Name, 3-char abbreviation, 1-char abbreviation</td><td align="left">None</td></tr><tr><td colspan="3"><hr/></td></tr><tr><td align="left">Chemical formulas</td><td align="left">Within a single token</td><td align="left">None</td></tr><tr><td colspan="3"><hr/></td></tr><tr><td align="left">Amino acid sequences</td><td align="left">Across tokens</td><td align="left">None</td></tr><tr><td colspan="3"><hr/></td></tr><tr><td align="left">Context window</td><td align="left">2</td><td align="left">3</td></tr><tr><td colspan="3"><hr/></td></tr><tr><td align="left" colspan="3"><bold>Post processing</bold></td></tr><tr><td colspan="3"><hr/></td></tr><tr><td align="left">Consistency</td><td align="left">Yes</td><td align="left">No</td></tr><tr><td colspan="3"><hr/></td></tr><tr><td align="left">Abbreviation resolution</td><td align="left">Yes</td><td align="left">Yes</td></tr><tr><td colspan="3"><hr/></td></tr><tr><td align="left">Parenthesis balancing</td><td align="left">Yes</td><td align="left">Yes</td></tr><tr><td colspan="3"><hr/></td></tr><tr><td align="left">Chemical identifiers</td><td align="left">Yes</td><td align="left">Yes</td></tr></tbody></table><table-wrap-foot><p>This table compares the setup and configuration of Model 1 and Model 2.</p></table-wrap-foot></table-wrap></sec><sec><title>CRF model 1</title><p>Model 1 is an adaptation of BANNER [<xref ref-type="bibr" rid="B22">22</xref>], which is built on the MALLET toolkit [<xref ref-type="bibr" rid="B25">25</xref>], to chemical entities. Sentence segmentation is performed by the built-in Java class BreakIterator. The tokenization is finer than typically used for genes or diseases, breaking tokens not only at white space and punctuation but also between letters and digits and also between lower case letters followed by an uppercase letter. An example of the tokenization is provided in Figure <xref ref-type="fig" rid="F2">2</xref>. We used the IOB label set with only one entity label ("CHEMICAL"), a CRF order of 1, and L<sub>2 </sub>regularization using the default Gaussian prior variance, 1.0.</p><fig id="F2" position="float"><label>Figure 2</label><caption><p><bold>Sample text illustrating tokenization differences between Model 1 and Model 2</bold>.</p></caption><graphic xlink:href="1758-2946-7-S1-S3-2"/></fig><p>The feature set combines both features previously used in BANNER and additional features added to improve performance on chemicals. These additional features were developed through many rounds of iterative design involving training the model and analysing the results on our internal evaluation set. We describe the set of features as follows:</p><p>&#x02022; Individual tokens and lemmas: We include a series of binary features indicating whether the token matches any token seen in the training data. We also include a series of binary features for the lemma for the token.</p><p>&#x02022; Part of speech: We include a series of binary features for each part of speech.</p><p>&#x02022; Word shapes: we process the token to inform the model about its pattern of letters and digits. All uppercase letters are replaced by "A," lowercase letters by "a," digits by "0" and all other characters by "x." The results are used as a binary feature.</p><p>&#x02022; Capitalization patterns: We employ several binary features to indicate whether the token matches one of several capitalization patterns, such as all capital letters.</p><p>&#x02022; Roman numerals and Greek letters: These are binary features which recognize if the token represents either a Roman numeral (e.g. "III") or the name of a Greek letter ("alpha").</p><p>&#x02022; Character n-grams of length 2 through 4: Chemicals are rich in morphemes that are either semantically meaningful, rare in text outside of chemistry, or both. We therefore include character n-gram features of length 2 through 4, which is longer than typically used for genes and diseases.</p><p>&#x02022; ChemSpot: The output of the ChemSpot system is used as a feature [<xref ref-type="bibr" rid="B4">4</xref>], providing functionality similar to a lexicon but with increased flexibility. We implement this as a binary feature, with any token overlapping a mention found by ChemSpot receiving the value 1, and all others 0.</p><p>&#x02022; Chemical elements: We use a list of element symbols ("Tc") and element names ("Technetium"), as found in [<xref ref-type="bibr" rid="B26">26</xref>], to create two binary features. These features recognize whether a token matches the name of a chemical symbol or element, respectively.</p><p>&#x02022; Amino acids: We also use a list of amino acid names and both 3-character and 1-character amino acid abbreviations, as found in [<xref ref-type="bibr" rid="B1">1</xref>], to create three binary features. These features respectively recognize whether a token matches the name of an amino acid, one of the 3-character abbreviations or one of the 1-character abbreviations.</p><p>&#x02022; Chemical formulas: We determined that chemical formulas were represented in text in ways that were too variable to capture with straightforward pattern matching. Instead, we decided to allow the machine learning model handle the recognition of formulas statistically. To facilitate this, we used a pattern to identify tokens consisting of a sequence of element symbols, such as "FCH," the first token in the formula "FCH2CH2N3."</p><p>&#x02022; Amino acid sequences: We used a pattern to recognize sequences of amino acids such as "Phe-Cys-Tyr," which crosses multiple tokens.</p><p>The total number of feature weights used in Model 1 is 794,979.</p></sec><sec><title>CRF model 2</title><p>We developed a second CRF model using the CRF++ library [<xref ref-type="bibr" rid="B23">23</xref>] by repurposing part of the tmVar system for locating genetic variants [<xref ref-type="bibr" rid="B24">24</xref>]. Since the system which provided the initial implementation for Model 2 had a significantly different purpose and implementation than Model 1, the final models also contained significant differences.</p><p>Non-ASCII Unicode characters are transliterated to a similar ASCII equivalent, such as converting Greek alpha ("&#x003b1;") to the letter "a." No sentence segmentation is used. The tokenization is the same as tmVar; specifically, tokens are separated at whitespace and punctuation, digits, lowercase letters and uppercase letters are divided into separate tokens [<xref ref-type="bibr" rid="B24">24</xref>]. An example of the tokenization is provided in Figure <xref ref-type="fig" rid="F2">2</xref>. This model also uses the IOB label set, but uses an order 2 CRF model. It also uses L<sub>2 </sub>regularization, with a Gaussian prior variance set to 4.0. The feature cut-off threshold was set to 3, meaning that features that do not appear at least three times in the training data are not used.</p><p>This model was adapted iteratively through analysis of the evaluation set. Since the initial system is different than BANNER, the final resulting feature set is different than Model 1, as described below:</p><p>&#x02022; General linguistic features: We included the original token and stems using the Porter stemmer [<xref ref-type="bibr" rid="B27">27</xref>].</p><p>&#x02022; Prefixes and suffixes: We extracted the prefixes and suffixes (length: 1 to 5) as features.</p><p>&#x02022; Character features: IUPAC mentions (e.g., "3-(4,5-dimethyl-thiazol-2-yl)-2-5-diphenyltetrazolium-bromide") include many digits and non-alphanumeric characters. For each token we therefore calculated several statistics, including the number of characters, number of digits and number of uppercase and lowercase letters, and use these as features.</p><p>&#x02022; Roman numerals and Greek letters: These are binary features which recognize if the token represents either a Roman numeral (e.g. "III") or the name of a Greek letter ("alpha").</p><p>&#x02022; Semantic features: We defined several binary features representing characteristics specific to chemicals, including suffixes (e.g. "-yl," "-oyl," "-one," "-ate," "acid," etc.), alkane stems (e.g. "meth," "eth," "prop" and "tetracos"), trivial rings (e.g. "benzene," "pyridine" and "toluene") and simple multipliers ("di," "tri" and "tetra"), as derived from [<xref ref-type="bibr" rid="B28">28</xref>].</p><p>&#x02022; Chemical elements: We included a binary feature to recognize the names of the chemical elements (e.g. "hydrogen") [<xref ref-type="bibr" rid="B26">26</xref>].</p><p>&#x02022; Case pattern features: We applied the case pattern features from tmVar [<xref ref-type="bibr" rid="B24">24</xref>]. Each token is represented in a simplified form. Upper case alphabetic characters are replaced by "A" and lower case characters are replaced by "a." Likewise, digits (0-9) are replaced by "0." Moreover, we also merged consecutive letters and numbers and generated additional single letter "a" and number "0" as features.</p><p>&#x02022; Contextual features: We included the general linguistic and semantic features of three tokens from each side as context. This is larger than for Model 1, which uses only two tokens on each side.</p><p>Our analysis of the results of ChemSpot on our internal evaluation set demonstrated good performance for long chemical mentions but relatively low recall for the short mentions that constitute the majority of the annotations in the CHEMDNER corpus. However our analysis of Model 2 already demonstrated good performance on long chemical mentions, and strong features such as the output of a system like ChemSpot tend to strongly bias conditional random field models. Thus, we did not use the output of ChemSpot as a feature for Model 2, even though it helped Model 1, and this difference helps to preserve the independence of the two models. The total number of feature weights used in Model 2 is 96,435,808, two orders of magnitude more than in Model 1.</p></sec><sec><title>Post-processing methods</title><p>We employed several post-processing steps, which varied slightly between Models 1 and 2. These steps include enforcing tagging consistency, abbreviation resolution, boundary revision to balance parenthesis, and recognizing identifiers.</p><p>We improved consistency - and significantly improved recall - by tagging all instances of a specific character sequence as a chemical mention if that sequence was tagged by the CRF model at least twice within an abstract. For example, if the CRF model found two instances of "steroidal saponins," a FAMILY mention, within an abstract but missed a third instance, the missed instance would be added. We further modified this module after the CHEMDNER task to not add mentions that overlap with mentions already tagged, for example to not add a tag for "GO" if "GO-PDEA" is already tagged. This module was only used by Model 1, since the output of Model 2 was found to be already be sufficiently consistent that this rule did not improve performance.</p><p>We used the Ab3P tool to find local abbreviation definitions, such as "allopregnanolone (AP)" [<xref ref-type="bibr" rid="B29">29</xref>]. In both models, if the long form was tagged by the CRF model, then all instances of the abbreviation would be tagged in the result. Model 2 employed two additional rules that were not found to help Model 1. First, if both the abbreviation and long form mention were tagged by the CRF model, then all mentions of the long form would be tagged. Second, if the long form mention was not tagged, then mentions matching the abbreviation were removed.</p><p>While there are several mentions in the training data with unbalanced parenthesis, square brackets and curly brackets (braces), we determined that virtually all of the unbalanced mentions returned by either of our models were errors. We therefore attempt to balance each mention with respect to parenthesis, square brackets and curly brackets (braces) by adding or removing one character to the right or left of the mention. For example, if the model tags "Cu(2+" and the next character in the text is a right parenthesis (")"), then the mention is extended to include it. If no variant of adding or removing one character to the right or left results in balanced parenthesis, we simply drop the mention. This module is used by both Models 1 and 2.</p><p>Chemical identifiers do not have a specific format, making them very difficult to identify with machine learning. We therefore created a lexicon of chemical identifiers from the CTD database <ext-link ext-link-type="uri" xlink:href="http://ctdbase.org/">http://ctdbase.org/</ext-link> by extracting the chemical names consisting of 2 to 5 letters, followed by at least two digits. We apply these as patterns, allowing the characters between the letter and digit blocks to vary. For example, the lexicon name "NSC-114792" becomes the regular expression "NSC[\-\_ ]{0,2}114792". This module is also used by both Model 1 and 2.</p></sec><sec><title>Converting CEM results to CDI results</title><p>The CDI task requires informative confidence rankings for each mention. Model 1 used an approximation of the marginal probability for each mention, that is, the probability that the mention is correct, to calculate the probability that the mention appears at least once in the abstract.</p><p>Unfortunately, the MALLET implementation of marginal probability only provides the marginal probability of each label. We therefore approximate the marginal probability of each mention using <italic>n</italic>-best inference, which determines the <italic>n </italic>label sequences with the highest joint probability [<xref ref-type="bibr" rid="B30">30</xref>]. We find the set of mentions present in the <italic>n </italic>= 20 label sequences with the highest joint probability, and then consider the marginal probability of each mention to be the sum of the joint probabilities of the label sequences where the mention appears.</p><p>To calculate the probability that the mention appears at least once in the abstract, we employ an assumption that each mention is independent of the others, and apply the <italic>noisy or </italic>function, which combines the probability that the mention appears with its frequency within the abstract in a natural way [<xref ref-type="bibr" rid="B31">31</xref>]. Specifically, given that a text <italic>t </italic>is found as a mention <italic>n </italic>times in abstract <italic>a</italic>, with mention-level probabilities <inline-formula><mml:math id="M1" name="1758-2946-7-S1-S3-i1" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo class="MathClass-open">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo class="MathClass-close">)</mml:mo></mml:mrow></mml:math></inline-formula> through <inline-formula><mml:math id="M2" name="1758-2946-7-S1-S3-i2" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo class="MathClass-open">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo class="MathClass-close">)</mml:mo></mml:mrow></mml:math></inline-formula>, the abstract-level probability for t, <italic>p<sup>a</sup></italic>(<italic>t</italic>), is calculated as:</p><p><disp-formula><mml:math id="M3" name="1758-2946-7-S1-S3-i3" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo class="MathClass-open">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo class="MathClass-close">)</mml:mo></mml:mrow><mml:mo class="MathClass-rel">=</mml:mo><mml:mn>1</mml:mn><mml:mo class="MathClass-bin">-</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mrow><mml:mo>&#x0220f;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo class="MathClass-rel">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mo class="MathClass-open">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo class="MathClass-bin">-</mml:mo><mml:msubsup><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo class="MathClass-open">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo class="MathClass-close">)</mml:mo></mml:mrow></mml:mrow><mml:mo class="MathClass-close">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>CRF++ does not provide implementations of either marginal probability or <italic>n</italic>-best decoding, so Model 2 instead uses a small fixed probability.</p></sec><sec><title>Model combinations</title><p>We take advantage of the differences between Model 1 and Model 2 to combine their results in three different ways. The "na&#x000ef;ve combination" merely pools the results from Model 1 and Model 2. We noted during analysis of the evaluation set that Model 2 had higher performance on short mentions, and consequently provide a "heuristic combination" which uses the results from Model 1 but replaces mentions of length 5 to 15 with the corresponding results from Model 2. Our "high recall combination" combines the mentions returned by n-best decoding in Model 1 with at least a marginal probability of 0.1 - which provides high recall while maintaining reasonable precision - with the results from Model 2.</p></sec><sec><title>Normalization</title><p>While recognizing chemical mentions is valuable, many tasks ultimately require the mention to be identified or normalized. We have thus paired our named entity recognition system with a straightforward lexical approach for normalization. Our lexicon of chemical entities and their names was collected from MeSH [<xref ref-type="bibr" rid="B32">32</xref>] and ChEBI [<xref ref-type="bibr" rid="B33">33</xref>]. The system converts both mentions from the literature and entity names in the lexicon to lowercase and removes all whitespace and punctuation. For example, "flavone-C-glycoside" becomes "flavonecglycoside." The system then assigns a MeSH identifier to those mentions which can be found in the lexicon, or a ChEBI identifier if a matching MeSH identifier cannot be found. Mentions that correspond to a short form recognized by Ab3P are assigned the same identifier as the long form found by Ab3P [<xref ref-type="bibr" rid="B29">29</xref>]. Mentions which do not map to a specific identifier are ignored and mentions which can be assigned to both a MeSH and ChEBI identifier are only assigned the MeSH identifier.</p></sec></sec><sec sec-type="results"><title>Results</title><p>The evaluation measures consisted of precision (the proportion of mentions returned that are correct), recall (the proportion of correct mentions that are returned) and f-measure (the harmonic mean of precision and recall). In the CEM task, a true positive (<italic>tp</italic>) consists of the system returning a mention whose boundaries exactly match the boundaries of a mention annotated in the test data. False positives (<italic>fp</italic>) are defined as the system returning a mention whose boundaries do not match any mention annotated in the test data, and false negatives (<italic>fn</italic>) are defined as a mention annotated in the test data whose boundaries do not match any mention returned by the system. The performance measurements for the CDI task are defined similarly, except that instead of requiring mention boundaries to match, the match must be the mention texts. Given these definitions, precision (<italic>p)</italic>, recall (<italic>r</italic>) and f-measure (<italic>f</italic>) are defined as:</p><p><disp-formula><mml:math id="M4" name="1758-2946-7-S1-S3-i4" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo class="MathClass-rel">=</mml:mo><mml:mfrac><mml:mrow><mml:mi>t</mml:mi><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>p</mml:mi><mml:mo class="MathClass-bin">+</mml:mo><mml:mi>f</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:mfrac><mml:mspace class="quad" width="1em"/><mml:mi>r</mml:mi><mml:mo class="MathClass-rel">=</mml:mo><mml:mfrac><mml:mrow><mml:mi>t</mml:mi><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>p</mml:mi><mml:mo class="MathClass-bin">+</mml:mo><mml:mi>f</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:mspace class="quad" width="1em"/><mml:mi>f</mml:mi><mml:mo class="MathClass-rel">=</mml:mo><mml:mn>2</mml:mn><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mo class="MathClass-bin">&#x022c5;</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo class="MathClass-bin">+</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>We report two sets of performance values: one on our internal evaluation set and one on the official test set. The internal evaluation set was created by pooling the official training and development data, then randomly splitting this pool into 6000 abstracts for training (internal training set) and 1000 abstracts for evaluation during development (internal evaluation set). The performance values for the internal evaluation set were created by training each model on the internal training set and evaluating on the internal evaluation set. The performance values for the official test set were created by training each model on the union of the official training and development sets, then evaluating on the official test set. Overall results for the CEM task are reported in Table <xref ref-type="table" rid="T2">2</xref> and results per chemical entity subtype are reported in Table <xref ref-type="table" rid="T3">3</xref>. Overall results for the CDI task are reported in Table <xref ref-type="table" rid="T4">4</xref>.</p><table-wrap id="T2" position="float"><label>Table 2</label><caption><p>Results for CEM task.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Setup</th><th align="left" colspan="3">Internal Evaluation Set</th><th align="left" colspan="3">Official Test Set</th></tr><tr><th/><th colspan="6"><hr/></th></tr><tr><th/><th align="left">P</th><th align="left">R</th><th align="left">F</th><th align="left">P</th><th align="left">R</th><th align="left">F</th></tr></thead><tbody><tr><td align="left">Model 1</td><td align="left">0.8773</td><td align="left">0.8758</td><td align="left">0.8766</td><td align="left">0.8595</td><td align="left">0.8721</td><td align="left">0.8657</td></tr><tr><td colspan="7"><hr/></td></tr><tr><td align="left">Model 2</td><td align="left"><bold>0.8781</bold></td><td align="left">0.8634</td><td align="left">0.8707</td><td align="left"><bold>0.8909</bold></td><td align="left">0.8575</td><td align="left"><bold>0.8739</bold></td></tr><tr><td colspan="7"><hr/></td></tr><tr><td align="left">Na&#x000ef;ve combination</td><td align="left">0.8323</td><td align="left"><bold>0.9290</bold></td><td align="left">0.8780</td><td align="left">0.8192</td><td align="left">0.9209</td><td align="left">0.8671</td></tr><tr><td colspan="7"><hr/></td></tr><tr><td align="left">Heuristic combination</td><td align="left">0.8659</td><td align="left">0.9002</td><td align="left"><bold>0.8827</bold></td><td align="left">0.8516</td><td align="left">0.8906</td><td align="left">0.8706</td></tr><tr><td colspan="7"><hr/></td></tr><tr><td align="left">High recall combination</td><td align="left">0.7651</td><td align="left"><bold>0.9290</bold></td><td align="left">0.8391</td><td align="left">0.7672</td><td align="left"><bold>0.9212</bold></td><td align="left">0.8372</td></tr></tbody></table><table-wrap-foot><p>Results for the CEM task for each experimental setup on our internal evaluation set and the official test set, as measured by micro-averaged precision (P), recall (R) and f-measure (F). The highest value is shown in bold.</p></table-wrap-foot></table-wrap><table-wrap id="T3" position="float"><label>Table 3</label><caption><p>Results for CEM task per chemical entity subtype.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Setup</th><th align="left">ABBR</th><th align="left">FAMI</th><th align="left">FORM</th><th align="left">IDEN</th><th align="left">MULT</th><th align="left">SYST</th><th align="left">TRIV</th><th align="left">NONE</th></tr></thead><tbody><tr><td align="left">Model 1</td><td align="left">0.8768</td><td align="left">0.8216</td><td align="left">0.8199</td><td align="left">0.8323</td><td align="left">0.3969</td><td align="left">0.9136</td><td align="left">0.9013</td><td align="left">0.7073</td></tr><tr><td colspan="9"><hr/></td></tr><tr><td align="left">Model 2</td><td align="left">0.8285</td><td align="left">0.7871</td><td align="left">0.8393</td><td align="left">0.8615</td><td align="left">0.4824</td><td align="left">0.9196</td><td align="left">0.8783</td><td align="left">0.6829</td></tr><tr><td colspan="9"><hr/></td></tr><tr><td align="left">Na&#x000ef;ve combination</td><td align="left">0.9132</td><td align="left">0.8799</td><td align="left">0.8936</td><td align="left">0.9005</td><td align="left">0.5326</td><td align="left">0.9588</td><td align="left">0.9403</td><td align="left">0.7804</td></tr><tr><td colspan="9"><hr/></td></tr><tr><td align="left">Heuristic combination</td><td align="left">0.8837</td><td align="left">0.8440</td><td align="left">0.8318</td><td align="left">0.8986</td><td align="left">0.4020</td><td align="left">0.9276</td><td align="left">0.9273</td><td align="left">0.7804</td></tr><tr><td colspan="9"><hr/></td></tr><tr><td align="left">High recall combination</td><td align="left">0.9137</td><td align="left">0.9006</td><td align="left">0.8809</td><td align="left">0.8752</td><td align="left">0.6030</td><td align="left">0.9525</td><td align="left">0.9414</td><td align="left">0.7560</td></tr></tbody></table><table-wrap-foot><p>Results for the CEM task for each experimental setup on each chemical entity subtype, as measured by micro-averaged recall.</p></table-wrap-foot></table-wrap><table-wrap id="T4" position="float"><label>Table 4</label><caption><p>Results for CDI task.</p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th align="left" colspan="3">Internal Evaluation Set</th><th align="left" colspan="3">Official Test Set</th></tr><tr><th/><th colspan="6"><hr/></th></tr><tr><th align="left">Setup</th><th align="left">P</th><th align="left">R</th><th align="left">F</th><th align="left">P</th><th align="left">R</th><th align="left">F</th></tr></thead><tbody><tr><td align="left">Model 1</td><td align="left"><bold>0.8732</bold></td><td align="left">0.8664</td><td align="left">0.8698</td><td align="left"><bold>0.8804</bold></td><td align="left">0.8606</td><td align="left">0.8704</td></tr><tr><td colspan="7"><hr/></td></tr><tr><td align="left">Model 2</td><td align="left">0.8572</td><td align="left">0.8806</td><td align="left">0.8687</td><td align="left">0.8781</td><td align="left">0.8724</td><td align="left"><bold>0.8752</bold></td></tr><tr><td colspan="7"><hr/></td></tr><tr><td align="left">Na&#x000ef;ve combination</td><td align="left">0.8138</td><td align="left"><bold>0.9270</bold></td><td align="left">0.8667</td><td align="left">0.8268</td><td align="left">0.9189</td><td align="left">0.8704</td></tr><tr><td colspan="7"><hr/></td></tr><tr><td align="left">Heuristic combination</td><td align="left">0.8565</td><td align="left">0.8934</td><td align="left"><bold>0.8745</bold></td><td align="left">0.8663</td><td align="left">0.8825</td><td align="left">0.8743</td></tr><tr><td colspan="7"><hr/></td></tr><tr><td align="left">High recall combination</td><td align="left">0.7422</td><td align="left"><bold>0.9270</bold></td><td align="left">0.8244</td><td align="left">0.7629</td><td align="left"><bold>0.9224</bold></td><td align="left">0.8351</td></tr></tbody></table></table-wrap></sec><sec sec-type="discussion"><title>Discussion</title><p>There is a notable difference in the results between the evaluation set and the test set. The results on the evaluation set followed the expected trends. Model 1 and Model 2 have similar performance. The na&#x000ef;ve model combination of the Model 1 and Model 2 results improves recall at the expense of precision, the heuristic combination in provides the highest f-measure, and our high recall combination provides the highest recall. The primary difference in the test set is a reduction in precision for Model 1, resulting in a reduction in f-measure by over 1%. While a performance reduction of this magnitude is not unusual, this contrasts with Model 2, where an increase in precision causes the f-measure to increase. These trends carry over into the combination runs. The difference between the CDI results are smaller than the difference between the CEM results, presumably due to the use of the marginal probability in Model 1. The f-measure achieved by Model 2 on the CEM task was the highest achieved by any submission to the CHEMDNER task.</p><sec><title>Error analysis</title><p>In other entity types such as genes, proteins and diseases, determining the entity type of tokens not observed in the training set is frequently difficult and must often rely on context. Many tokens in chemical mentions have highly distinctive features, however, which frequently allows the model to infer that the token is part of a chemical mention even if the token has not been seen previously. The greater problem for chemicals seems to be determining the mention boundaries, where errors cause a significant performance reduction since each boundary error results in both a false positive and a false negative under the common practice of assigning each token to at most one mention. We found, for example, that allowing boundaries to overlap instead of match exactly resulted in an f-measure for Model 1 of over 0.92.</p><p>One issue which causes boundary errors in many entity types is modifiers, since whether the modifier is considered part of the mention or not depends on the both the modifier and the core term. Our error analysis found many cases of boundary errors due to modifiers, such as returning "aromatic hydrocarbons" instead of "polycyclic aromatic hydrocarbons" or returning "Gynostemma pentaphyllum saponins" instead of "saponins." We anticipate that improving the modelling of tokens not seen during training could address these cases.</p><p>Another issue common in other entity types is mentions containing coordination ellipsis [<xref ref-type="bibr" rid="B34">34</xref>], such as "oleic, linoleic, and palmitic acids." We observed both models having difficulties finding complete coordinations, instead, we often observed the models locating the non-elliptical part of the mention (such as "3-O-alkyl clarithromycin" from the mention "3-hydroxyl, 3-O-acyl and 3-O-alkyl clarithromycin"). It seems likely that existing methods to handle coordination based on supervised machine learning, such as [<xref ref-type="bibr" rid="B35">35</xref>], would be effective in many of these cases. However, we believe that fully effective coordination resolution may be a considerable challenge due to the significant complexity of many coordinated chemical mentions (e.g. "ribo and 2'-b-C-methyl ribo Janus type nucleosides"). These mentions may benefit from a method that combines coordination resolution with a lexical approach, such as [<xref ref-type="bibr" rid="B34">34</xref>].</p><p>Another phenomenon more specific to chemicals relates to the use of systematic and formula names. While some chemical names - typically TRIVIAL names - are relatively short and possess comparatively unambiguous boundaries, chemical formulas and systematic names are descriptive terminologies whose productivity mirrors the infinite array of possible chemicals. Since lists of chemicals and chemical compounds are annotated as separate mentions, the classifier must decide after every token whether to extend the current mention or whether the next token begins a new mention. While one would expect some subtypes to be more fixed (e.g. TRIVIAL and FAMILY) and other to trend more toward extensibility (e.g. SYSTEMATIC and FORMULA), we instead observed that the annotated chemical subtypes did not provide sufficient information to allow the models to reliably differentiate between them. For example, some mentions annotated as subtype FAMILY trend towards extensibility (e.g. "2-acetamido-3-mercapto-3-methyl-N-aryl-butanamides") while some SYSTEMATIC mentions would be considered as relatively fixed phrases (e.g. "phthalate"). The primary need for handling this problem is to provide some way to model mention completeness. This could be handled in many ways. A lexical approach would attempt to ensure completeness of chemical entity mentions by referring to a lexicon of chemical entities. A rule-based method would provide the same information, but may allow IUPAC and other systematic nomenclatures to be recognized directly. These methods both model mention completeness indirectly by determining the identity of the chemical entity mentioned. An unsupervised method to model completeness directly might attempt to locate the same mention in a large amount of unlabelled text, where the boundaries may be less ambiguous [<xref ref-type="bibr" rid="B36">36</xref>,<xref ref-type="bibr" rid="B37">37</xref>].</p><p>Non-boundary errors were of several types. One significant source of error is short proteins. Because proteins are large molecules with specific functions, they are essentially highly specialized chemicals. However the CHEMDNER task defined chemicals from the structural composition perspective, specifically defining peptides 15 amino acids or longer as biochemical entities, which are not annotated. Thus, relatively short proteins such as "kaliotoxin" and "thioredocin-1" are often mentioned in the abstracts with a discussion of their uses and effects, similar to chemicals, but are considered false positives when found because their length in amino acids exceeds the threshold set for annotation. Since determining if these mentions are chemicals requires integrating knowledge that is often not present in the abstract, resolving these cases requires identifying the mention, suggesting that named entity recognition and normalization are not always independent steps.</p><p>Abbreviations are highly ambiguous, and while our use of abbreviation post-processing significantly helped with their recognition, we found that Ab3P was not as successful at locating the full mentions as in our recent work on diseases [<xref ref-type="bibr" rid="B9">9</xref>]. The primary reason appears to be non-alphabetic characters at the beginning of the long form of the name, such as "1,2,3,4,6 penta-O-galloyl-b-d-glucose (PGG)." We anticipate that updating the abbreviation model to anticipate non-alphabetic content at the beginning of the long form which is not reflected in the short form would largely resolve this issue.</p></sec><sec><title>Differences between the models</title><p>We performed a series of experiments to explore which differences between Model 1 and Model 2 caused the performance differences between the two models. In these experiments we chose the aspects of Model 2 we considered most likely to improve the performance of Model 1. These differences were then implemented in Model 1, applied one at a time, and performance recalculated. To clarify exposition, we describe these differences in two sets.</p><p>The first set of differences we considered were the finer tokenization, the model order (order 2 instead of 1), the size of the feature context window (3 instead of 2), and the Unicode transliteration preprocessing. All experiments from this set resulted in a reduction to both precision and recall on both the Evaluation and Test sets (data not shown).</p><p>The second set of differences we considered were the Gaussian prior variance and the feature frequency threshold. The Gaussian prior variance (&#x003c3;) controls the strength of the regularization, so that reducing &#x003c3; lowers the ability of the model to fit the data, increasing generalization and decreasing the chance of overfitting. During the task, Model 1 used &#x003c3; = 1.0, the default, while Model 2 used &#x003c3; = 4.0. The feature frequency threshold (c) specifies that any feature appearing in a positive context fewer times than the threshold would not be included in the model. Model 1 did not use a feature frequency threshold during the task (effectively 0), while the threshold was set to 3 for Model 2. Increasing the frequency threshold should result in increased model stability, though this may come at the expense of ignoring some useful rare signals.</p><p>Since a model with more stable features should require less regularization, we expected that it would be useful to optimize &#x003c3; and c together. We therefore ran a series of 16 experiments, jointly varying the values of &#x003c3; and c in Model 1 between &#x003c3; = {0.5, 1.0, 2.0, 4.0} and c = {0, 1, 3, 5}. Contrary to our expectation, we found no clear relationship between either &#x003c3; or c and the resulting performance (data not shown). We did determine, however, that performance on the Evaluation set was generally predictive of performance on the Test set. The highest precision on the Evaluation set was provided by &#x003c3; = 1.0 and c = 0 - the default configuration - and the highest recall and f-measure were provided by &#x003c3; = 2.0 and c = 1. While these configurations also performed very well on the Test set, the configuration with the highest f-measure on the Test set was &#x003c3; = 0.5 and c = 5, primarily due to unexpectedly high precision. The performance of these configurations is described in Table <xref ref-type="table" rid="T5">5</xref>.</p><table-wrap id="T5" position="float"><label>Table 5</label><caption><p>Model 1 CEM results for optimizing Gaussian prior variance and feature frequency threshold.</p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th align="left" colspan="3">Internal Evaluation Set</th><th align="left" colspan="3">Official Test Set</th></tr><tr><th/><th colspan="6"><hr/></th></tr><tr><th align="left">Setup</th><th align="left">P</th><th align="left">R</th><th align="left">F</th><th align="left">P</th><th align="left">R</th><th align="left">F</th></tr></thead><tbody><tr><td align="left">&#x003c3; = 1.0, c = 0</td><td align="left"><bold>0.8773</bold></td><td align="left">0.8758</td><td align="left">0.8766</td><td align="left">0.8595</td><td align="left"><bold>0.8721</bold></td><td align="left">0.8657</td></tr><tr><td colspan="7"><hr/></td></tr><tr><td align="left">&#x003c3; = 2.0, c = 1</td><td align="left">0.8758</td><td align="left"><bold>0.8778</bold></td><td align="left"><bold>0.8768</bold></td><td align="left">0.8973</td><td align="left">0.8474</td><td align="left">0.8716</td></tr><tr><td colspan="7"><hr/></td></tr><tr><td align="left">&#x003c3; = 0.5, c = 5</td><td align="left">0.8766</td><td align="left">0.8731</td><td align="left">0.8749</td><td align="left"><bold>0.9009</bold></td><td align="left">0.8462</td><td align="left"><bold>0.8727</bold></td></tr></tbody></table><table-wrap-foot><p>Model 1 results for the CEM task for the Gaussian prior variance (&#x003c3;) value and feature frequency threshold (c) value, which resulted in the highest micro-averaged precision (P), recall (R) and f-measure (F) on our internal evaluation set and the official test set. The highest value is shown in bold.</p><p>Results for the CDI task for each experimental setup on our internal evaluation set and the official test set, as measured by micro-averaged precision (P), recall (R), and f-measure (F). The highest value is shown in bold.</p></table-wrap-foot></table-wrap><p>These results suggest that jointly optimizing &#x003c3; and c is useful and that the best advice is to use the configuration that performs best on the Evaluation set. It should also be noted, however, that the difference between the highest and lowest result for precision, recall and f-measure (after removing the configuration &#x003c3; = 0.5, c = 0, which performed poorly) are all relatively small, approximately 0.01 (data not shown).</p><p>While these experiments have not exhaustively tested every difference between the two models, most of the differences between Model 1 and Model 2 caused a reduction in performance when ported to Model 1. This result suggests that the models are in fact independent. The differences which improved performance - optimizing the feature frequency threshold (c) and the regularization parameter (the Gaussian prior variance, &#x003c3;) allowed Model 1 to approach the performance of Model 2, however.</p></sec></sec><sec sec-type="conclusions"><title>Conclusions</title><p>We used a model combination approach where the two models have many differences. The models used different tokenizations, feature sets, CRF implementations, CRF parameters, and some variations in post processing. This is in contrast to most previous NER work on model combination, where many models are used but they typically differ in only a single aspect, such as the model order [<xref ref-type="bibr" rid="B30">30</xref>]. Many of the remaining differences reduce performance when the models are modified to be more alike.</p><p>Model 1 experienced a slight drop in performance between the Evaluation and Test sets, while the performance of Model 2 increased slightly. Model 2 achieved the highest f-measure reported on the CEM task. Our model combination runs succeeded in providing higher recall, and we found our approach of preparing and combining multiple CRF models and post-processing to be effective overall. Unfortunately, combining the results of multiple models incurs some inconvenience for practical use, and the large size of the file containing the trained parameters for Model 2 (over 1 Gb) may limit widespread use. Regardless, both Model 1 and Model 2 are available at our supplementary website (see abstract for the URL). Moreover, the results of a full run of Model 2 over PubMed is available in PubTator [<xref ref-type="bibr" rid="B6">6</xref>,<xref ref-type="bibr" rid="B38">38</xref>], including normalization using the lexical approach described in the Methods section.</p><p>We note that tmChem is now able to report performance for mention-level detection of chemicals competitive with (or even greater than) the performance typically reported for genes, proteins and diseases. In addition, our error analysis uncovered several problems where further development would likely improve performance. Interestingly, most of these would clearly benefit from providing the named entity recognition step with an informative signal regarding the identity of the chemical entity being mentioned. Like gene and other concept recognition tasks [<xref ref-type="bibr" rid="B9">9</xref>,<xref ref-type="bibr" rid="B39">39</xref>], it is important to investigate how to normalize detected chemical mentions to standard terminologies or ontologies in future studies.</p></sec><sec><title>Authors' contributions</title><p>Conceived and designed the experiments: RL, CHW and ZL. Performed the experiments: RL and CHW. Drafted the manuscript: RL, CHW and ZL. All authors read and approved the manuscript.</p></sec><sec><title>Competing interests</title><p>The authors declare that they have no competing interests.</p></sec></body><back><sec><title>Acknowledgements</title><p>The organizers would thank the organizers of the BioCreative 4 CHEMDNER task.</p></sec><sec><title>Declarations</title><p>This research and publication was supported by the Intramural Research Program of the NIH, National Library of Medicine. The authors declare that they have no competing interests.</p><p>This article has been published as part of <italic>Journal of Cheminformatics </italic>Volume 7 Supplement 1, 2015: Text mining for chemistry and the CHEMDNER track. The full contents of the supplement are available online at <ext-link ext-link-type="uri" xlink:href="http://www.jcheminf.com/supplements/7/S1">http://www.jcheminf.com/supplements/7/S1</ext-link>.</p></sec><ref-list><ref id="B1"><mixed-citation publication-type="book"><name><surname>Hunter</surname><given-names>LE</given-names></name><source>The Processes of Life: An Introduction to Molecular Biology</source><year>2009</year><publisher-name>MIT Press</publisher-name></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="journal"><name><surname>Neveol</surname><given-names>A</given-names></name><name><surname>Islamaj Dogan</surname><given-names>R</given-names></name><name><surname>Lu</surname><given-names>Z</given-names></name><article-title>Semi-automatic semantic annotation of PubMed queries: a study on quality, efficiency, satisfaction</article-title><source>J Biomed Inform</source><year>2011</year><volume>44</volume><issue>2</issue><fpage>310</fpage><lpage>318</lpage><pub-id pub-id-type="doi">10.1016/j.jbi.2010.11.001</pub-id><pub-id pub-id-type="pmid">21094696</pub-id></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal"><name><surname>Islamaj Dogan</surname><given-names>R</given-names></name><name><surname>Murray</surname><given-names>GC</given-names></name><name><surname>Neveol</surname><given-names>A</given-names></name><name><surname>Lu</surname><given-names>Z</given-names></name><article-title>Understanding PubMed user search behavior through log analysis</article-title><source>Database (Oxford)</source><year>2009</year><volume>2009</volume><fpage>bap018</fpage><pub-id pub-id-type="pmid">20157491</pub-id></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><name><surname>Rocktaschel</surname><given-names>T</given-names></name><name><surname>Weidlich</surname><given-names>M</given-names></name><name><surname>Leser</surname><given-names>U</given-names></name><article-title>ChemSpot: A Hybrid System for Chemical Named Entity Recognition</article-title><source>Bioinformatics</source><year>2012</year><volume>28</volume><issue>12</issue><fpage>1633</fpage><lpage>1640</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/bts183</pub-id><pub-id pub-id-type="pmid">22500000</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><name><surname>Smith</surname><given-names>L</given-names></name><name><surname>Tanabe</surname><given-names>LK</given-names></name><name><surname>Ando</surname><given-names>RJ</given-names></name><name><surname>Kuo</surname><given-names>CJ</given-names></name><name><surname>Chung</surname><given-names>IF</given-names></name><name><surname>Hsu</surname><given-names>CN</given-names></name><name><surname>Lin</surname><given-names>YS</given-names></name><name><surname>Klinger</surname><given-names>R</given-names></name><name><surname>Friedrich</surname><given-names>CM</given-names></name><name><surname>Ganchev</surname><given-names>K</given-names></name><name><surname>Torii</surname><given-names>M</given-names></name><name><surname>Liu</surname><given-names>H</given-names></name><name><surname>Haddow</surname><given-names>B</given-names></name><name><surname>Struble</surname><given-names>CA</given-names></name><name><surname>Povinelli</surname><given-names>RJ</given-names></name><name><surname>Vlachos</surname><given-names>A</given-names></name><name><surname>Baumgartner</surname><given-names>WA</given-names></name><name><surname>Hunter</surname><given-names>L</given-names></name><name><surname>Carpenter</surname><given-names>B</given-names></name><name><surname>Tsai</surname><given-names>RT</given-names></name><name><surname>Dai</surname><given-names>HJ</given-names></name><name><surname>Liu</surname><given-names>F</given-names></name><name><surname>Chen</surname><given-names>Y</given-names></name><name><surname>Sun</surname><given-names>C</given-names></name><name><surname>Katrenko</surname><given-names>S</given-names></name><name><surname>Adriaans</surname><given-names>P</given-names></name><name><surname>Blaschke</surname><given-names>C</given-names></name><name><surname>Torres</surname><given-names>R</given-names></name><name><surname>Neves</surname><given-names>M</given-names></name><name><surname>Nakov</surname><given-names>P</given-names></name><etal/><article-title>Overview of BioCreative II gene mention recognition</article-title><source>Genome Biol</source><year>2008</year><volume>9</volume><issue>Suppl 2</issue><fpage>S2</fpage><pub-id pub-id-type="doi">10.1186/gb-2008-9-s2-s2</pub-id><pub-id pub-id-type="pmid">18834493</pub-id></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><name><surname>Wei</surname><given-names>CH</given-names></name><name><surname>Kao</surname><given-names>HY</given-names></name><name><surname>Lu</surname><given-names>Z</given-names></name><article-title>PubTator: a web-based text mining tool for assisting biocuration</article-title><source>Nucleic Acids Res</source><year>2013</year><volume>41</volume><issue>W1</issue><fpage>W518</fpage><lpage>W522</lpage><pub-id pub-id-type="doi">10.1093/nar/gkt441</pub-id><pub-id pub-id-type="pmid">23703206</pub-id></mixed-citation></ref><ref id="B7"><mixed-citation publication-type="other"><name><surname>Islamaj Do&#x0011f;an</surname><given-names>R</given-names></name><name><surname>Lu</surname><given-names>Z</given-names></name><article-title>An improved corpus of disease mentions in PubMed citations</article-title><source>Proceedings of the ACL 2012 Workshop on BioNLP</source><year>2012</year><fpage>91</fpage><lpage>99</lpage></mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><name><surname>Wei</surname><given-names>CH</given-names></name><name><surname>Kao</surname><given-names>HY</given-names></name><name><surname>Lu</surname><given-names>Z</given-names></name><article-title>SR4GN: a species recognition software tool for gene normalization</article-title><source>PloS one</source><year>2012</year><volume>7</volume><issue>6</issue><fpage>e38460</fpage><pub-id pub-id-type="doi">10.1371/journal.pone.0038460</pub-id><pub-id pub-id-type="pmid">22679507</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="journal"><name><surname>Leaman</surname><given-names>R</given-names></name><name><surname>Do&#x0011f;an</surname><given-names>RI</given-names></name><name><surname>Lu</surname><given-names>Z</given-names></name><article-title>DNorm: Disease name normalization with pairwise learning-to-rank</article-title><source>Bioinformatics</source><year>2013</year><volume>29</volume><issue>22</issue><fpage>2909</fpage><lpage>2917</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btt474</pub-id><pub-id pub-id-type="pmid">23969135</pub-id></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="journal"><name><surname>Vazquez</surname><given-names>M</given-names></name><name><surname>Krallinger</surname><given-names>M</given-names></name><name><surname>Leitner</surname><given-names>F</given-names></name><name><surname>Valencia</surname><given-names>A</given-names></name><article-title>Text Mining for Drugs and Chemical Compounds: Methods, Tools and Applications</article-title><source>Molecular Informatics</source><year>2011</year><volume>30</volume><issue>6-7</issue><fpage>506</fpage><lpage>519</lpage><pub-id pub-id-type="doi">10.1002/minf.201100005</pub-id></mixed-citation></ref><ref id="B11"><mixed-citation publication-type="journal"><name><surname>Eltyeb</surname><given-names>S</given-names></name><name><surname>Salim</surname><given-names>N</given-names></name><article-title>Chemical named entities recognition: a review on approaches and applications</article-title><source>Journal of cheminformatics</source><year>2014</year><volume>6</volume><fpage>17</fpage><pub-id pub-id-type="doi">10.1186/1758-2946-6-17</pub-id><pub-id pub-id-type="pmid">24834132</pub-id></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="journal"><name><surname>Hettne</surname><given-names>KM</given-names></name><name><surname>Stierum</surname><given-names>RH</given-names></name><name><surname>Schuemie</surname><given-names>MJ</given-names></name><name><surname>Hendriksen</surname><given-names>PJ</given-names></name><name><surname>Schijvenaars</surname><given-names>BJ</given-names></name><name><surname>Mulligen</surname><given-names>EM</given-names></name><name><surname>Kleinjans</surname><given-names>J</given-names></name><name><surname>Kors</surname><given-names>JA</given-names></name><article-title>A dictionary to identify small molecules and drugs in free text</article-title><source>Bioinformatics</source><year>2009</year><volume>25</volume><issue>22</issue><fpage>2983</fpage><lpage>2991</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btp535</pub-id><pub-id pub-id-type="pmid">19759196</pub-id></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="journal"><name><surname>Klinger</surname><given-names>R</given-names></name><name><surname>Kolarik</surname><given-names>C</given-names></name><name><surname>Fluck</surname><given-names>J</given-names></name><name><surname>Hofmann-Apitius</surname><given-names>M</given-names></name><name><surname>Friedrich</surname><given-names>CM</given-names></name><article-title>Detection of IUPAC and IUPAC-like chemical names</article-title><source>Bioinformatics</source><year>2008</year><volume>24</volume><issue>13</issue><fpage>i268</fpage><lpage>276</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btn181</pub-id><pub-id pub-id-type="pmid">18586724</pub-id></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="journal"><name><surname>Jessop</surname><given-names>DM</given-names></name><name><surname>Adams</surname><given-names>SE</given-names></name><name><surname>Willighagen</surname><given-names>EL</given-names></name><name><surname>Hawizy</surname><given-names>L</given-names></name><name><surname>Murray-Rust</surname><given-names>P</given-names></name><article-title>OSCAR4: a flexible architecture for chemical text-mining</article-title><source>Journal of cheminformatics</source><year>2011</year><volume>3</volume><issue>1</issue><fpage>41</fpage><pub-id pub-id-type="doi">10.1186/1758-2946-3-41</pub-id><pub-id pub-id-type="pmid">21999457</pub-id></mixed-citation></ref><ref id="B15"><mixed-citation publication-type="other"><name><surname>Kolarik</surname><given-names>C</given-names></name><name><surname>Klinger</surname><given-names>R</given-names></name><name><surname>Friedrich</surname><given-names>CM</given-names></name><name><surname>Hoffmann-Apitius</surname><given-names>M</given-names></name><name><surname>Fluck</surname><given-names>J</given-names></name><article-title>Chemical names: terminological resources and corpora annotation</article-title><source>Workshop on building and evaluating resources for biomedical text mining (6th edition of the Language Resources and Evaluation Conference)</source><year>2008</year></mixed-citation></ref><ref id="B16"><mixed-citation publication-type="journal"><name><surname>Rebholz-Schuhmann</surname><given-names>D</given-names></name><name><surname>Jimeno Yepes</surname><given-names>A</given-names></name><name><surname>Li</surname><given-names>C</given-names></name><name><surname>Kafkas</surname><given-names>S</given-names></name><name><surname>Lewin</surname><given-names>I</given-names></name><name><surname>Kang</surname><given-names>N</given-names></name><name><surname>Corbett</surname><given-names>P</given-names></name><name><surname>Milward</surname><given-names>D</given-names></name><name><surname>Buyko</surname><given-names>E</given-names></name><name><surname>Beisswanger</surname><given-names>E</given-names></name><name><surname>Hornbostel</surname><given-names>K</given-names></name><name><surname>Kouznetsov</surname><given-names>A</given-names></name><name><surname>Witte</surname><given-names>R</given-names></name><name><surname>Laurila</surname><given-names>JB</given-names></name><name><surname>Baker</surname><given-names>CJ</given-names></name><name><surname>Kuo</surname><given-names>CJ</given-names></name><name><surname>Clematide</surname><given-names>S</given-names></name><name><surname>Rinaldi</surname><given-names>F</given-names></name><name><surname>Farkas</surname><given-names>R</given-names></name><name><surname>Mora</surname><given-names>G</given-names></name><name><surname>Hara</surname><given-names>K</given-names></name><name><surname>Furlong</surname><given-names>LI</given-names></name><name><surname>Rautschka</surname><given-names>M</given-names></name><name><surname>Neves</surname><given-names>ML</given-names></name><name><surname>Pascual-Montano</surname><given-names>A</given-names></name><name><surname>Wei</surname><given-names>Q</given-names></name><name><surname>Collier</surname><given-names>N</given-names></name><name><surname>Chowdhury</surname><given-names>MF</given-names></name><name><surname>Lavelli</surname><given-names>A</given-names></name><name><surname>Berlanga</surname><given-names>R</given-names></name><etal/><article-title>Assessment of NER solutions against the first and second CALBC Silver Standard Corpus</article-title><source>Journal of biomedical semantics</source><year>2011</year><volume>2</volume><issue>Suppl 5</issue><fpage>S11</fpage><pub-id pub-id-type="doi">10.1186/2041-1480-2-S5-S11</pub-id><pub-id pub-id-type="pmid">22166494</pub-id></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="journal"><name><surname>Rebholz-Schuhmann</surname><given-names>D</given-names></name><name><surname>Jimeno Yepes</surname><given-names>AJ</given-names></name><name><surname>Van Mulligen</surname><given-names>EM</given-names></name><name><surname>Kang</surname><given-names>N</given-names></name><name><surname>Kors</surname><given-names>J</given-names></name><name><surname>Milward</surname><given-names>D</given-names></name><name><surname>Corbett</surname><given-names>P</given-names></name><name><surname>Buyko</surname><given-names>E</given-names></name><name><surname>Beisswanger</surname><given-names>E</given-names></name><name><surname>Hahn</surname><given-names>U</given-names></name><article-title>CALBC silver standard corpus</article-title><source>Journal of bioinformatics and computational biology</source><year>2010</year><volume>8</volume><issue>1</issue><fpage>163</fpage><lpage>179</lpage><pub-id pub-id-type="doi">10.1142/S0219720010004562</pub-id><pub-id pub-id-type="pmid">20183881</pub-id></mixed-citation></ref><ref id="B18"><mixed-citation publication-type="journal"><name><surname>Krallinger</surname><given-names>M</given-names></name><name><surname>Leitner</surname><given-names>F</given-names></name><name><surname>Rabal</surname><given-names>O</given-names></name><name><surname>Vazquez</surname><given-names>M</given-names></name><name><surname>Oyarzabal</surname><given-names>J</given-names></name><name><surname>Valencia</surname><given-names>A</given-names></name><article-title>CHEMDNER: The drugs and chemical names extraction challenge</article-title><source>J Cheminform</source><year>2015</year><volume>7</volume><issue>Suppl 1</issue><fpage>S1</fpage></mixed-citation></ref><ref id="B19"><mixed-citation publication-type="other"><name><surname>Leaman</surname><given-names>R</given-names></name><name><surname>Wei</surname><given-names>CH</given-names></name><name><surname>Lu</surname><given-names>Z</given-names></name><article-title>NCBI at the BioCreative IV CHEMDNER Task: Recognizing chemical names in PubMed articles with tmChem</article-title><source>Fourth BioCreative Challenge Evaluation; Bethesda, Maryland, USA</source><year>2013</year><fpage>34</fpage><lpage>41</lpage><pub-id pub-id-type="pmid">25006225</pub-id></mixed-citation></ref><ref id="B20"><mixed-citation publication-type="journal"><name><surname>Krallinger</surname><given-names>M</given-names></name><name><surname>Rabal</surname><given-names>O</given-names></name><name><surname>Leitner</surname><given-names>F</given-names></name><name><surname>Vazquez</surname><given-names>M</given-names></name><name><surname>Salgado</surname><given-names>D</given-names></name><name><surname>Lu</surname><given-names>Z</given-names></name><name><surname>Leaman</surname><given-names>R</given-names></name><name><surname>Lu</surname><given-names>Y</given-names></name><name><surname>Ji</surname><given-names>D</given-names></name><name><surname>Lowe</surname><given-names>DM</given-names></name><name><surname>Sayle</surname><given-names>RA</given-names></name><name><surname>Batista-Navarro</surname><given-names>RT</given-names></name><name><surname>Rak</surname><given-names>R</given-names></name><name><surname>Huber</surname><given-names>T</given-names></name><name><surname>Rocktaschel</surname><given-names>T</given-names></name><name><surname>Matos</surname><given-names>S</given-names></name><name><surname>Campos</surname><given-names>D</given-names></name><name><surname>Tang</surname><given-names>B</given-names></name><name><surname>Xu</surname><given-names>H</given-names></name><name><surname>Munkhdalai</surname><given-names>T</given-names></name><name><surname>Ryu</surname><given-names>KH</given-names></name><name><surname>Ramanan</surname><given-names>SV</given-names></name><name><surname>Nathan</surname><given-names>S</given-names></name><name><surname>Zitnik</surname><given-names>S</given-names></name><name><surname>Bajec</surname><given-names>M</given-names></name><name><surname>Weber</surname><given-names>L</given-names></name><name><surname>Irmer</surname><given-names>M</given-names></name><name><surname>Akhondi</surname><given-names>SA</given-names></name><name><surname>Kors</surname><given-names>JA</given-names></name><name><surname>Xu</surname><given-names>S</given-names></name><name><surname>An</surname><given-names>X</given-names></name><name><surname>Sikdar</surname><given-names>UK</given-names></name><name><surname>Ekbal</surname><given-names>A</given-names></name><name><surname>Yoshioka</surname><given-names>M</given-names></name><name><surname>Dieb</surname><given-names>TM</given-names></name><name><surname>Choi</surname><given-names>M</given-names></name><name><surname>Verspoor</surname><given-names>K</given-names></name><name><surname>Khabsa</surname><given-names>M</given-names></name><name><surname>Giles</surname><given-names>CL</given-names></name><name><surname>Liu</surname><given-names>H</given-names></name><name><surname>Ravikumar</surname><given-names>KE</given-names></name><name><surname>Lamurias</surname><given-names>A</given-names></name><name><surname>Couto</surname><given-names>FM</given-names></name><name><surname>Dai</surname><given-names>H</given-names></name><name><surname>Tsai</surname><given-names>RT</given-names></name><name><surname>Ata</surname><given-names>C</given-names></name><name><surname>Can</surname><given-names>T</given-names></name><name><surname>Usie</surname><given-names>A</given-names></name><name><surname>Alves</surname><given-names>R</given-names></name><name><surname>Segura-Bedmar</surname><given-names>I</given-names></name><name><surname>Martinez</surname><given-names>P</given-names></name><name><surname>Oryzabal</surname><given-names>J</given-names></name><name><surname>Valencia</surname><given-names>A</given-names></name><article-title>The CHEMDNER corpus of chemicals and drugs and its annotation principles</article-title><source>J Cheminform</source><year>2015</year><volume>7</volume><issue>Suppl 1</issue><fpage>S2</fpage></mixed-citation></ref><ref id="B21"><mixed-citation publication-type="book"><name><surname>Hastie</surname><given-names>T</given-names></name><name><surname>Tibshirani</surname><given-names>R</given-names></name><name><surname>Friedman</surname><given-names>J</given-names></name><source>The Elements of Statistical Learning</source><year>2009</year><edition>Second</edition><publisher-name>Springer</publisher-name></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="other"><name><surname>Leaman</surname><given-names>R</given-names></name><name><surname>Gonzalez</surname><given-names>G</given-names></name><article-title>BANNER: an executable survey of advances in biomedical named entity recognition</article-title><source>Pac Symp Biocomput</source><year>2008</year><fpage>652</fpage><lpage>663</lpage><pub-id pub-id-type="pmid">18229723</pub-id></mixed-citation></ref><ref id="B23"><mixed-citation publication-type="other"><name><surname>Kudo</surname><given-names>T</given-names></name><article-title>CRF++: Yet Another CRF Toolkit</article-title><ext-link ext-link-type="uri" xlink:href="https://code.google.com/p/crfpp">https://code.google.com/p/crfpp</ext-link></mixed-citation></ref><ref id="B24"><mixed-citation publication-type="journal"><name><surname>Wei</surname><given-names>C-H</given-names></name><name><surname>Harris</surname><given-names>BR</given-names></name><name><surname>Kao</surname><given-names>H-Y</given-names></name><name><surname>Lu</surname><given-names>Z</given-names></name><article-title>tmVar: A text mining approach for extracting sequence variants in biomedical literature</article-title><source>Bioinformatics</source><year>2013</year><volume>29</volume><fpage>1433</fpage><lpage>1439</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btt156</pub-id><pub-id pub-id-type="pmid">23564842</pub-id></mixed-citation></ref><ref id="B25"><mixed-citation publication-type="other"><name><surname>McCallum</surname><given-names>A</given-names></name><article-title>MALLET: A Machine Learning for Language Toolkit</article-title><ext-link ext-link-type="uri" xlink:href="http://mallet.cs.umass.edu">http://mallet.cs.umass.edu</ext-link></mixed-citation></ref><ref id="B26"><mixed-citation publication-type="book"><name><surname>Timberlake</surname><given-names>KC</given-names></name><source>Chemistry: An Introduction to General, Organic, and Biological Chemistry</source><year>2011</year><edition>11</edition><publisher-name>Prentice Hall</publisher-name></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="journal"><name><surname>Porter</surname><given-names>MF</given-names></name><article-title>An algorithm for suffix stripping</article-title><source>Program</source><year>1980</year><volume>14</volume><fpage>130</fpage><lpage>137</lpage><pub-id pub-id-type="doi">10.1108/eb046814</pub-id></mixed-citation></ref><ref id="B28"><mixed-citation publication-type="journal"><name><surname>Lowe</surname><given-names>DM</given-names></name><name><surname>Corbett</surname><given-names>PT</given-names></name><name><surname>Murray-Rust</surname><given-names>P</given-names></name><name><surname>Glen</surname><given-names>RC</given-names></name><article-title>Chemical name to structure: OPSIN, an open source solution</article-title><source>Journal of chemical information and modeling</source><year>2011</year><volume>51</volume><issue>3</issue><fpage>739</fpage><lpage>753</lpage><pub-id pub-id-type="doi">10.1021/ci100384d</pub-id><pub-id pub-id-type="pmid">21384929</pub-id></mixed-citation></ref><ref id="B29"><mixed-citation publication-type="journal"><name><surname>Sohn</surname><given-names>S</given-names></name><name><surname>Comeau</surname><given-names>DC</given-names></name><name><surname>Kim</surname><given-names>W</given-names></name><name><surname>Wilbur</surname><given-names>WJ</given-names></name><article-title>Abbreviation definition identification based on automatic precision estimates</article-title><source>BMC Bioinformatics</source><year>2008</year><volume>9</volume><fpage>402</fpage><pub-id pub-id-type="doi">10.1186/1471-2105-9-402</pub-id><pub-id pub-id-type="pmid">18817555</pub-id></mixed-citation></ref><ref id="B30"><mixed-citation publication-type="journal"><name><surname>Hsu</surname><given-names>CN</given-names></name><name><surname>Chang</surname><given-names>YM</given-names></name><name><surname>Kuo</surname><given-names>CJ</given-names></name><name><surname>Lin</surname><given-names>YS</given-names></name><name><surname>Huang</surname><given-names>HS</given-names></name><name><surname>Chung</surname><given-names>IF</given-names></name><article-title>Integrating high dimensional bi-directional parsing models for gene mention tagging</article-title><source>Bioinformatics</source><year>2008</year><volume>24</volume><issue>13</issue><fpage>i286</fpage><lpage>294</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btn183</pub-id><pub-id pub-id-type="pmid">18586726</pub-id></mixed-citation></ref><ref id="B31"><mixed-citation publication-type="book"><name><surname>Pearl</surname><given-names>J</given-names></name><source>Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference</source><year>1988</year><publisher-name>San Mateo, California, USA: Morgan Kaufmann</publisher-name></mixed-citation></ref><ref id="B32"><mixed-citation publication-type="journal"><name><surname>Coletti</surname><given-names>MH</given-names></name><name><surname>Bleich</surname><given-names>HL</given-names></name><article-title>Medical subject headings used to search the biomedical literature</article-title><source>J Am Med Inform Assoc</source><year>2001</year><volume>8</volume><issue>4</issue><fpage>317</fpage><lpage>323</lpage><pub-id pub-id-type="doi">10.1136/jamia.2001.0080317</pub-id><pub-id pub-id-type="pmid">11418538</pub-id></mixed-citation></ref><ref id="B33"><mixed-citation publication-type="journal"><name><surname>de Matos</surname><given-names>P</given-names></name><name><surname>Dekker</surname><given-names>A</given-names></name><name><surname>Ennis</surname><given-names>M</given-names></name><name><surname>Hastings</surname><given-names>J</given-names></name><name><surname>Haug</surname><given-names>K</given-names></name><name><surname>Turner</surname><given-names>S</given-names></name><name><surname>Steinbeck</surname><given-names>C</given-names></name><article-title>ChEBI: a chemistry ontology and database</article-title><source>Journal of cheminformatics</source><year>2010</year><volume>2</volume><issue>Suppl 1</issue><fpage>P6</fpage><lpage>P6</lpage><pub-id pub-id-type="doi">10.1186/1758-2946-2-S1-P6</pub-id></mixed-citation></ref><ref id="B34"><mixed-citation publication-type="journal"><name><surname>Chae</surname><given-names>J</given-names></name><name><surname>Jung</surname><given-names>Y</given-names></name><name><surname>Lee</surname><given-names>T</given-names></name><name><surname>Jung</surname><given-names>S</given-names></name><name><surname>Huh</surname><given-names>C</given-names></name><name><surname>Kim</surname><given-names>G</given-names></name><name><surname>Kim</surname><given-names>H</given-names></name><name><surname>Oh</surname><given-names>H</given-names></name><article-title>Identifying non-elliptical entity mentions in a coordinated NP with ellipses</article-title><source>J Biomed Inform</source><year>2014</year><volume>47</volume><fpage>139</fpage><lpage>152</lpage><pub-id pub-id-type="pmid">24153413</pub-id></mixed-citation></ref><ref id="B35"><mixed-citation publication-type="other"><name><surname>Buyko</surname><given-names>E</given-names></name><name><surname>Tomanek</surname><given-names>K</given-names></name><name><surname>Hahn</surname><given-names>U</given-names></name><article-title>Resolution of coordination ellipses in biological named entities using conditional random fields</article-title><source>Proceedings of the Conference of the Pacific Association for Computational Linguistics</source><year>2007</year><fpage>163</fpage><lpage>171</lpage></mixed-citation></ref><ref id="B36"><mixed-citation publication-type="journal"><name><surname>Zhang</surname><given-names>S</given-names></name><name><surname>Elhadad</surname><given-names>N</given-names></name><article-title>Unsupervised biomedical named entity recognition: experiments with clinical and biological texts</article-title><source>J Biomed Inform</source><year>2013</year><volume>46</volume><issue>6</issue><fpage>1088</fpage><lpage>1098</lpage><pub-id pub-id-type="doi">10.1016/j.jbi.2013.08.004</pub-id><pub-id pub-id-type="pmid">23954592</pub-id></mixed-citation></ref><ref id="B37"><mixed-citation publication-type="other"><name><surname>Leaman</surname><given-names>JR</given-names></name><article-title>Advancing Biomedical Named Entity Recognition with Multivariate Feature Selection and Semantically Motivated Features</article-title><source>PhD Thesis. Arizona State University, School of Computing, Informatics, and Decision Systems Engineering</source><year>2013</year></mixed-citation></ref><ref id="B38"><mixed-citation publication-type="journal"><name><surname>Wei</surname><given-names>CH</given-names></name><name><surname>Harris</surname><given-names>BR</given-names></name><name><surname>Li</surname><given-names>D</given-names></name><name><surname>Berardini</surname><given-names>TZ</given-names></name><name><surname>Huala</surname><given-names>E</given-names></name><name><surname>Kao</surname><given-names>HY</given-names></name><name><surname>Lu</surname><given-names>Z</given-names></name><article-title>Accelerating literature curation with text-mining tools: a case study of using PubTator to curate genes in PubMed abstracts</article-title><source>Database (Oxford)</source><year>2012</year><volume>2012</volume><fpage>bas041</fpage><pub-id pub-id-type="pmid">23160414</pub-id></mixed-citation></ref><ref id="B39"><mixed-citation publication-type="journal"><name><surname>Lu</surname><given-names>Z</given-names></name><name><surname>Kao</surname><given-names>HY</given-names></name><name><surname>Wei</surname><given-names>CH</given-names></name><name><surname>Huang</surname><given-names>M</given-names></name><name><surname>Liu</surname><given-names>J</given-names></name><name><surname>Kuo</surname><given-names>CJ</given-names></name><name><surname>Hsu</surname><given-names>CN</given-names></name><name><surname>Tsai</surname><given-names>RT</given-names></name><name><surname>Dai</surname><given-names>HJ</given-names></name><name><surname>Okazaki</surname><given-names>N</given-names></name><name><surname>Cho</surname><given-names>HC</given-names></name><name><surname>Gerner</surname><given-names>M</given-names></name><name><surname>Solt</surname><given-names>I</given-names></name><name><surname>Agarwal</surname><given-names>S</given-names></name><name><surname>Liu</surname><given-names>F</given-names></name><name><surname>Vishnyakova</surname><given-names>D</given-names></name><name><surname>Ruch</surname><given-names>P</given-names></name><name><surname>Romacker</surname><given-names>M</given-names></name><name><surname>Rinaldi</surname><given-names>F</given-names></name><name><surname>Bhattacharya</surname><given-names>S</given-names></name><name><surname>Srinivasan</surname><given-names>P</given-names></name><name><surname>Liu</surname><given-names>H</given-names></name><name><surname>Torii</surname><given-names>M</given-names></name><name><surname>Matos</surname><given-names>S</given-names></name><name><surname>Campos</surname><given-names>D</given-names></name><name><surname>Verspoor</surname><given-names>K</given-names></name><name><surname>Livingston</surname><given-names>KM</given-names></name><name><surname>Wilbur</surname><given-names>WJ</given-names></name><article-title>The gene normalization task in BioCreative III</article-title><source>BMC Bioinformatics</source><year>2011</year><volume>12</volume><issue>Suppl 8</issue><fpage>S2</fpage><pub-id pub-id-type="doi">10.1186/1471-2105-12-S8-S2</pub-id><pub-id pub-id-type="pmid">22151901</pub-id></mixed-citation></ref></ref-list></back></article>