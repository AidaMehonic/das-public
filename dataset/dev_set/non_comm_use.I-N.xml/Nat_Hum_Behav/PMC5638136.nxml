<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><?properties manuscript?><front><journal-meta><journal-id journal-id-type="nlm-journal-id">101697750</journal-id><journal-id journal-id-type="pubmed-jr-id">46015</journal-id><journal-id journal-id-type="nlm-ta">Nat Hum Behav</journal-id><journal-id journal-id-type="iso-abbrev">Nat Hum Behav</journal-id><journal-title-group><journal-title>Nature human behaviour</journal-title></journal-title-group><issn pub-type="epub">2397-3374</issn></journal-meta><article-meta><article-id pub-id-type="pmid">29034334</article-id><article-id pub-id-type="pmc">5638136</article-id><article-id pub-id-type="doi">10.1038/s41562-017-0107</article-id><article-id pub-id-type="manuscript">NIHMS865461</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Arousal-related adjustments of perceptual biases optimize perception in dynamic environments</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Krishnamurthy</surname><given-names>Kamesh</given-names></name><xref rid="FN2" ref-type="author-notes">*</xref><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Nassar</surname><given-names>Matthew R.</given-names></name><xref rid="FN2" ref-type="author-notes">*</xref><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><name><surname>Sarode</surname><given-names>Shilpa</given-names></name><xref ref-type="aff" rid="A3">3</xref></contrib><contrib contrib-type="author"><name><surname>Gold</surname><given-names>Joshua I</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib></contrib-group><aff id="A1">
<label>1</label>Department of Neuroscience, University of Pennsylvania 19104-6074</aff><aff id="A2">
<label>2</label>Department of Cognitive, Linguistic, and Psychological Sciences, Brown University 02912</aff><aff id="A3">
<label>3</label>Department of Electrical Engineering, University of Pennsylvania 19104-6074</aff><author-notes><corresp id="FN1">Corresponding Author: Joshua I. Gold, Department of Neuroscience, University of Pennsylvania, Philadelphia, PA 19104-6074, Phone: 215-746-0028, <email>jigold@mail.med.upenn.edu</email></corresp><fn id="FN2" fn-type="equal"><label>*</label><p>contributed equally and listed alphabetically</p></fn></author-notes><pub-date pub-type="nihms-submitted"><day>15</day><month>4</month><year>2017</year></pub-date><pub-date pub-type="epub"><day>8</day><month>5</month><year>2017</year></pub-date><pub-date pub-type="ppub"><year>2017</year></pub-date><pub-date pub-type="pmc-release"><day>08</day><month>11</month><year>2017</year></pub-date><volume>1</volume><elocation-id>0107</elocation-id><permissions><license><license-p>Users may view, print, copy, and download text and data-mine the content in such documents, for the purposes of academic research, subject always to the full Conditions of use:
<uri xlink:type="simple" xlink:href="http://www.nature.com/authors/editorial_policies/license.html#terms">http://www.nature.com/authors/editorial_policies/license.html#terms</uri></license-p></license></permissions><abstract><p id="P1">Prior expectations can be used to improve perceptual judgments about ambiguous stimuli. However, little is known about if and how these improvements are maintained in dynamic environments in which the quality of appropriate priors changes from one stimulus to the next. Using a sound-localization task, we show that changes in stimulus predictability lead to arousal-mediated adjustments in the magnitude of prior-driven biases that optimize perceptual judgments about each stimulus. These adjustments depend on task-dependent changes in the relevance and reliability of prior expectations, which subjects update using both normative and idiosyncratic principles. The resulting variations in biases across task conditions and individuals are reflected in modulations of pupil diameter, such that larger stimulus-evoked pupil responses correspond to smaller biases. These results suggest a critical role for the arousal system in adjusting the strength of perceptual biases with respect to inferred environmental dynamics to optimize perceptual judgements.</p></abstract></article-meta></front><body><sec sec-type="intro" id="S1"><title>Introduction</title><p id="P2">Perception is shaped by prior expectations (&#x0201c;priors&#x0201d;) on the statistical structure of the sensory world <sup><xref rid="R1" ref-type="bibr">1</xref>&#x02013;<xref rid="R6" ref-type="bibr">6</xref></sup>. When the environmental statistics are stationary and well known, priors on those statistics can bias the perception of relevant sensory stimuli <sup><xref rid="R7" ref-type="bibr">7</xref>,<xref rid="R8" ref-type="bibr">8</xref></sup>. For example, the prevalence of relatively slow-versus fast-moving objects in the world can lead to biases in the perception of object speed <sup><xref rid="R9" ref-type="bibr">9</xref></sup>. However, many environmental statistics that are relevant to perception can be highly non-stationary. For example, the locations of sources of sensory input are constantly changing relative to a given observer. The goal of this study was to examine how priors on such dynamic features of the environment are updated and used to shape perception.</p><p id="P3">To achieve this goal, we developed an auditory-localization task that required human subjects to both predict and report the perceived location of a simulated sound source as the predictability of the location varied over time (<xref rid="F1" ref-type="fig">Fig. 1a&#x02013;c</xref>). The statistical structure of the task is similar to ones we used previously to show that people can make effective predictions in dynamic environments by adaptively modulating the influence of new information on existing beliefs <sup><xref rid="R10" ref-type="bibr">10</xref>,<xref rid="R11" ref-type="bibr">11</xref></sup>. However, here we focus on the questions of if and how such dynamically modulated predictions affect their influence on the perception of ambiguous stimuli. In principle, these predictions could govern perceptual biases through a form of optimal (Bayesian) inference that takes into account dynamic changes in the priors <sup><xref rid="R10" ref-type="bibr">10</xref>,<xref rid="R12" ref-type="bibr">12</xref>,<xref rid="R13" ref-type="bibr">13</xref></sup>. Specifically, as long as the statistical structure of the sampled locations in our task remains stable, new sounds can be used to develop increasingly reliable priors about the locations of subsequent sounds. These increasingly reliable priors should, in turn, have an increasingly strong and beneficial influence on the perception of those sounds, reducing localization errors (<xref rid="F1" ref-type="fig">Fig. 1d,e</xref>). However, the statistics of the sampled locations can undergo abrupt change-points that render previously held priors irrelevant to new sounds. These seemingly reliable but irrelevant priors should not influence the perception of sound-source location, which under these conditions should be limited entirely by sensory uncertainty (<xref rid="F1" ref-type="fig">Fig. 1f</xref>).</p><p id="P4">We also measured pupil diameter, an index of arousal that can reflect the activation of the locus coeruleus (LC)-norepinephrine (NE) system and has been implicated in rapidly updating inference processes in response to unexpected events or errors <sup><xref rid="R14" ref-type="bibr">14</xref>&#x02013;<xref rid="R19" ref-type="bibr">19</xref></sup>. Pupil diameter tracks the extent to which predictions are updated in response to new information in dynamic and perceptually unambiguous cognitive tasks <sup><xref rid="R11" ref-type="bibr">11</xref></sup>. Here we tested the hypothesis that such changes in arousal play an important role in shaping perception. In particular, we examined whether the arousal system controls the extent to which perceptual judgments about ambiguous sensory stimuli are biased toward prior expectations in accordance with the relevance and reliability of those expectations.</p><p id="P5">Our results yield new insights into the relationship between perception and arousal. We show that the subjects&#x02019; priors had a variable influence on their perceptual reports. This variability was predicted by changes in the relevance and reliability of those priors, across task conditions and individual subjects. These effects were encoded in both baseline and stimulus-evoked changes in pupil diameter, such that larger diameters corresponded to less influence of priors on the perception of that stimulus. Taken together, these findings support a fundamental role for pupil-linked arousal systems, including the LC-NE system, in adaptively adjusting the influence of priors on perception in accordance with environmental dynamics.</p></sec><sec sec-type="results" id="S2"><title>Results</title><p id="P6">Twenty-nine subjects performed both the dynamic localization task (<xref rid="F1" ref-type="fig">Fig. 1</xref>) and a control task that required perceptual reports of simulated sound-source locations that lacked predictable, sequential structure. Overall, the subjects tended to perform both tasks in an effective manner, providing predictions on the dynamic task and perceptual reports on both tasks that corresponded strongly to the simulated sound-source locations (<xref rid="F2" ref-type="fig">Fig. 2</xref>). On the control task, the Pearson&#x02019;s correlation between simulated and reported location had median [interquartile range, or IQR] values of 0.926 [0.895&#x02013;0.944] across subjects (<xref rid="F2" ref-type="fig">Fig. 2a,d</xref>). On the dynamic task, there were similarly high correlations for both the predictions and perceptual reports (predictions on non-change-point trials: <italic>r</italic>=0.907 [0.895&#x02013;0.921], <xref rid="F2" ref-type="fig">Fig. 2b,e</xref>; perceptual reports on all trials: <italic>r</italic>=0.948 [0.941&#x02013;0.964], <xref rid="F2" ref-type="fig">Fig. 2c,f</xref>). However, the subjects also tended to make errors that varied considerably from trial to trial on both tasks (<xref rid="F2" ref-type="fig">Fig. 2g&#x02013;i</xref>). Subsequent analyses focus on how the subjects minimized their errors on the dynamic task by exploiting the fluctuating predictability of sound-source locations on that task.</p><sec id="S3"><title>Dynamic, task-dependent modulation of perceptual biases</title><p id="P7">The subjects used both sensory and prior information to guide their perceptual reports on the dynamic task. We measured performance in terms of the variability of the distribution of trial-by-trial errors (quantified as the standard deviation, or STD, and denoted as <italic>&#x003c3;</italic>). This variability was lower for perceptual reports on the dynamic task than for either: 1) predictions from that task (<italic>&#x003c3;<sub>prior</sub></italic>; <xref rid="F2" ref-type="fig">Fig. 2h</xref>), or 2) perceptual reports on the control task that lacked sequential predictability and thus reflected more purely sensory processing (<italic>&#x003c3;<sub>sensory</sub></italic>; <xref rid="F2" ref-type="fig">Fig. 2g</xref>). Moreover, for individual subjects, these different measures of variability were related to each other, such that perceptual errors from the dynamic task were well approximated using the optimal, reliability-weighted combination of prior and sensory information (
<inline-formula><mml:math id="M1" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">&#x003c3;</mml:mi><mml:mi mathvariant="italic">optimal</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi mathvariant="normal">&#x003c3;</mml:mi><mml:mi mathvariant="italic">Prior</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi mathvariant="normal">&#x003c3;</mml:mi><mml:mi mathvariant="italic">sensory</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>; <xref rid="F2" ref-type="fig">Fig. 2i</xref>). This result implies that, on average, the subjects tended to not only use these two sources of information, but also combine them according to their relative reliabilities to optimize perceptual performance on the dynamic task.</p><p id="P40">This integration of prior and sensory information took into account the changes in the relevance and reliability of the priors that occurred throughout the dynamic task. These changes are illustrated in <xref rid="F3" ref-type="fig">Fig. 3a</xref>, which shows prediction-error STDs averaged across subjects as a function of the number of sounds after a clearly noticeable change-point, or SAC (see legend for details), separately for the two noise conditions. <xref rid="F3" ref-type="fig">Figure 3b</xref> shows linear contrasts that captured the salient, dynamic aspects of these changes for each subject (see inset in <xref rid="F3" ref-type="fig">Fig. 3e</xref> illustrating the three contrasts: CP, describing the effects of a noticeable change-point; Exp, describing the effects of the number of sounds experienced following a noticeable change-point; and Noise, describing the high or low noise condition). Specifically, on change-point trials, predictions were irrelevant and hence most variable with respect to the subsequent sound-source location (signed-rank test for <italic>H<sub>0</sub></italic>: the median of the distribution of per-subject CP contrasts, which compared change-points to other trials=0, <italic>p</italic>&#x0003c;10<sup>&#x02212;5</sup>). After change-points, predictions became steadily more reliable as the number of sound sources experienced from the new distribution increased in both noise conditions (<italic>p</italic>&#x0003c;10<sup>&#x02212;4</sup> for Exp<sub>low</sub> and Exp<sub>high</sub> contrasts, which identified linear trends across SAC 2&#x02013;6 for each of the two noise conditions). The predictions were also more reliable overall in the low-versus high-noise condition (Noise contrast, <italic>p</italic>&#x0003c;10<sup>&#x02212;5</sup>). These dynamic trends were consistent with predictions from a normative model of predictive inference that had full knowledge of the generative statistics <sup><xref rid="R10" ref-type="bibr">10</xref></sup>. The model, which produced simulated predictions that were analyzed in the same way as the data, had task-dependent effects that were in the same directions and of roughly the same magnitude as the data, although the subjects tended to produce more variable predictions than the model (<xref rid="F3" ref-type="fig">Fig. 3a,b</xref> diamonds).</p><p id="P41">These task-dependent changes in the subjects&#x02019; predictions were associated with similar changes in the variability of their perceptual reports (<xref rid="F3" ref-type="fig">Fig. 3c,d</xref>) and their confidence in those reports, as assessed by the frequencies of high-confidence reports (<xref rid="F3" ref-type="fig">Fig. 3e,f</xref>). Perceptual-error variability tended to be higher for change-point trials, when predictions were irrelevant (CP contrast, <italic>p</italic>&#x0003c;10<sup>&#x02212;5</sup>), and for the high-versus low-noise condition (Noise contrast, <italic>p</italic>&#x0003c;10<sup>&#x02212;5</sup>). Perceptual-error variability also tended to decrease on experiencing more samples from the new distribution, with a reliable effect across individuals in the low-noise condition (Exp<sub>low</sub> contrast, <italic>p</italic>&#x0003c;0.005) but not the high-noise condition (Exp<sub>high</sub> contrast, <italic>p</italic>=0.4). These dynamics were also apparent in the subjects&#x02019; confidence report trends (<xref rid="F3" ref-type="fig">Fig. 3e,f</xref>), which reflected trial-by-trial awareness of the changes in perceptual variability and included similar dependencies on CP (<italic>p</italic>&#x0003c;10<sup>&#x02212;4</sup>), Noise (<italic>p</italic>=0.032), and Exp<sub>low</sub> (<italic>p</italic>=0.03) and less reliable dependencies on Exp<sub>high</sub> (<italic>p</italic>=0.07). Both the perceptual and confidence report effects were qualitatively similar, in direction and magnitude, to theoretical values computed from optimal combinations of each subjects&#x02019; changing priors (circles in <xref rid="F3" ref-type="fig">Fig. 3a,b</xref>) and their fixed sensory reliability estimated from the control task (<xref rid="F2" ref-type="fig">Fig. 2g</xref>; see also <xref rid="F1" ref-type="fig">Fig. 1d&#x02013;f</xref>). These theoretical values also showed strong effects of CP, Noise, and Exp<sub>low</sub>, and smaller effects of Exp<sub>high</sub> (<xref rid="F3" ref-type="fig">Fig. 3c&#x02013;f</xref>, diamonds).</p><p id="P42">These behavioral dynamics reflected changes in the degree to which the subjects&#x02019; priors biased their perceptual reports. We quantified perceptual bias as the slope of the relationship between the prediction error and the perceptual error measured on individual trials (<xref rid="F4" ref-type="fig">Fig. 4a&#x02013;c</xref>). A slope of zero implies no relationship between the prediction error and the perceptual error, and thus no bias towards the prior. In contrast, slope values that increase towards unity imply increasing biases of the perceptual reports towards the prior. This perceptual bias varied systematically as a function of task conditions. Specifically, perceptual bias was lower on change-points (CP contrast, <italic>p</italic>&#x0003c;10<sup>&#x02212;5</sup>) and for the high-versus low-noise condition (Noise contrast, <italic>p</italic>=0.008). Perceptual bias also tended to increase on experiencing more samples, although these effects were variable across individuals and not statistically reliable in the low-noise condition (Exp<sub>low</sub> contrast, <italic>p</italic>=0.1; Exp<sub>high</sub> contrast, <italic>p</italic>=0.004). These task-dependent changes in the biases were comparable in direction and magnitude to theoretically computed values given an optimal, reliability-weighted combination of the task-specific predictions on the dynamic task (circles in <xref rid="F3" ref-type="fig">Fig. 3a</xref>) and fixed sensory reliability estimated from the control task (<xref rid="F2" ref-type="fig">Fig. 2g</xref>), computed separately for each subject (diamonds in <xref rid="F4" ref-type="fig">Fig. 4d,e</xref>). Despite these comparable task-dependent trends (compare circles and diamonds in <xref rid="F4" ref-type="fig">Fig. 4e</xref>), the subjects&#x02019; perceptual biases were on average smaller than the theoretical values (compare circles and diamonds in <xref rid="F4" ref-type="fig">Fig. 4d</xref>). This shift was consistent with their overall worse predictions than the model (compare circles and diamonds in <xref rid="F3" ref-type="fig">Fig. 3a</xref>). However, overall performance, measured as perceptual-error variability, was relatively insensitive to this overall shift, as compared to task-dependent adjustments, in the magnitude of the perceptual biases (compare circles and triangles in <xref rid="F3" ref-type="fig">Fig. 3c,d</xref>).</p></sec><sec id="S4"><title>Individual differences in the modulation of perceptual biases</title><p id="P8">The above analyses demonstrated that for individual subjects, dynamic changes in the relevance and reliability of priors within an experimental session were associated with changes in the degree to which those priors biased perception. We identified similar effects across subjects, implying that individual differences in perception can reflect differences in how priors are updated and maintained in dynamic environments. Specifically, we compared subjects&#x02019; overall biases to the variability of their sensory and prediction errors (linear regression of the mean perceptual biases of individual subjects from non-change-point trials as a function of the STD of perceptual errors from the control task and the STD of prediction errors across non-change-point trials from the dynamic task; <italic>F</italic> statistic=7.39, <italic>p</italic>=0.002). According to these fits and consistent with Bayesian theory, subjects with higher overall prior-driven perceptual biases tended to have higher sensory variability (<italic>&#x003b2;</italic>=0.033, <italic>t</italic>-test for <italic>H<sub>0</sub></italic>: &#x003b2;<italic>=0, p</italic>=0.013; <xref rid="F5" ref-type="fig">Fig. 5a</xref>) and lower prediction variability (<italic>&#x003b2;</italic>=&#x02212;0.030, <italic>p</italic>=0.002; <xref rid="F5" ref-type="fig">Fig 5b</xref>). We also found individual differences in how perceptual biases changed as a function of particular task conditions, and that those differences were predicted by subject-specific changes in priors under those conditions. Subjects whose priors improved (i.e., became less variable) the most also tended to have the largest increases in prior-driven perceptual biases: 1) just after a change-point (<xref rid="F5" ref-type="fig">Fig. 5e</xref>), 2) on experiencing samples from a new distribution (in the low-but not high-noise condition; <xref rid="F5" ref-type="fig">Figs. 5c and d</xref>), or 3) between the high- and low-noise conditions (<xref rid="F5" ref-type="fig">Fig. 5f</xref>). Thus, on average, subjects tended to weigh prior and sensory information according to their relative reliabilities, taking into account variability in the priors across task conditions and individual subjects.</p><p id="P9">To more quantitatively account for the factors that affected perceptual biases across task conditions and individual subjects, we used a linear model that included normative and non-normative terms that each were weighed according to their contributions to each subject&#x02019;s behavior (<xref rid="F6" ref-type="fig">Fig. 6</xref>). Data generated by a purely normative model could capture some qualitative aspects of behaviour, but it systematically overestimated perceptual biases (<xref rid="F6" ref-type="fig">Fig 6A</xref>). A linear model that included both normative and non-normative terms offered a better description of behaviour (<xref rid="F6" ref-type="fig">Fig. 6B</xref>). The normative terms were extracted from a Bayesian model of perception, which generated perceptual biases that minimized simulated perceptual errors, given each subject&#x02019;s variable predictions and sensory estimates. These terms were: 1) prior relevance, which reflected the probability that the current sound came from the same generative distribution as the previous sound (and thus is related to the CP effects illustrated in <xref rid="F3" ref-type="fig">Figs. 3</xref> and <xref rid="F4" ref-type="fig">4</xref>; <xref rid="F6" ref-type="fig">Fig. 6c</xref>); and 2) prior reliability, which reflected changes in the total width of the predictive distribution relative to the likelihood, given new samples (and thus is related to the Exp and Noise effects illustrated in <xref rid="F3" ref-type="fig">Figs. 3</xref> and <xref rid="F4" ref-type="fig">4</xref>; <xref rid="F6" ref-type="fig">Fig. 6d</xref>). The non-normative terms included one describing a fixed bias as a function of the prediction error, one to allow the strength of perceptual bias to depend on reported confidence (i.e., whether the subject reported high confidence or not), and spatial terms to account for the subjects&#x02019; overall tendency to give perceptual reports that were biased slightly towards straight ahead (<xref rid="F2" ref-type="fig">Fig. 2f</xref>). On average, the linear model captured the behavioral trends well (<xref rid="F6" ref-type="fig">Fig. 6b</xref>), based on contributions of each of the terms described above that tended to vary in magnitude across subjects (<xref rid="F6" ref-type="fig">Fig. 6e</xref>). By comparison, a parameter-free normative model captured some of the behavioral trends (<xref rid="F6" ref-type="fig">Fig. 6a</xref>) but reported higher perceptual biases than subjects (compare red points and bar in <xref rid="F6" ref-type="fig">Fig. 6e</xref>), particularly on change-points (compare green points and bars in <xref rid="F6" ref-type="fig">Fig. 6e</xref>).</p></sec><sec id="S5"><title>Modulations of perceptual biases reflected in pupil diameter</title><p id="P10">A key question addressed in this work is whether arousal systems, as reflected in pupil diameter, contribute to the dynamic modulation of perceptual biases. Using linear regression at each time-point relative to sound onset (the average sound-evoked pupil response from all probe trials and subjects is shown in <xref rid="F7" ref-type="fig">Fig. 7a</xref>), we found that pupil diameter varied with several of the factors from the linear model that accounted for behavioral biases (<xref rid="FD6" ref-type="disp-formula">Eq. 6</xref>; <xref rid="F7" ref-type="fig">Fig. 7b</xref>). Specifically, prior reliability was reflected in the baseline diameter before presentation of the probe sound, with smaller baselines reflecting more reliable priors (<italic>p</italic>=0.03; <xref rid="F7" ref-type="fig">Fig. 7c,h</xref>). However, prior reliability did not modulate the magnitude of the stimulus-evoked pupil response, after accounting for the baseline effect (<xref rid="F7" ref-type="fig">Fig. 7f,i</xref>). In contrast, prior relevance was unrelated to baseline diameter but was robustly encoded by the stimulus-evoked pupil diameter, with larger evoked pupil responses reflecting lower prior relevance (<xref rid="F7" ref-type="fig">Fig. 7b,e</xref>). This effect peaked around the time of the maximum sound-evoked pupil response (permutation test for effect duration: duration=1.0 s, <italic>p</italic>=0.02; <xref rid="F7" ref-type="fig">Fig. 7i</xref>). The pupil response, but not the baseline, also reflected the subjects&#x02019; upcoming confidence report, with high confidence corresponding to larger pupil diameters, particularly late in the fixation interval (duration=1.8 s, <italic>p</italic>=0.01; <xref rid="F7" ref-type="fig">Fig. 7d,g,i</xref>; note that these duration estimates were limited by the size of our measurement window).</p><p id="P11">If the arousal system is contributing to the dynamic regulation of the influence of priors on perception, then pupil diameter may co-vary with adjustments in prior influence even after accounting for all of the factors in the behavioral linear model (for example, if variability in internal representations of sound-source location affect both behavior and arousal). We therefore included the residual perceptual bias from our model of behavior (<xref rid="F6" ref-type="fig">Fig. 6</xref>) in our model of pupil diameter. A positive/negative value of the residual biases indicates that the subject was more/less biased by the prior on the given trial than predicted by the linear model. There was a trend toward positive coefficients for this term in explaining baseline pupil diameter (larger baseline diameters corresponded to slightly stronger biases than predicted by the behavioral model; <italic>p</italic>=0.06; <xref rid="F7" ref-type="fig">Fig. 7h</xref>). In addition, there was a robust reflection of the residual bias term in sound-evoked pupil response (smaller responses near the peak of the evoked response corresponded to stronger biases than predicted by the behavioural model; duration=1.2 s, <italic>p</italic>=0.02; <xref rid="F7" ref-type="fig">Fig. 7i</xref>). This residual bias effect implies that pupil diameter reflects not just particular factors like prior reliability and relevance that can be used to make effective predictions in dynamic environments <sup><xref rid="R11" ref-type="bibr">11</xref></sup>, but also the extent to which those and other factors are actually used to bias perception from one stimulus to the next.</p><p id="P12">In addition to these average, within-subject effects, there were also across-subject relationships between pupil diameter and perceptual biases. In particular, stimulus-evoked pupil responses tended to be, on average, smaller in subjects with higher overall perceptual biases (PE term in <xref rid="F6" ref-type="fig">Fig. 6e</xref>; <xref rid="F8" ref-type="fig">Fig. 8c</xref>) or relevance-dependent biases (PE*relevance term in <xref rid="F6" ref-type="fig">Fig. 6e</xref>; <xref rid="F8" ref-type="fig">Fig. 8d</xref>). These effects were not evident for baseline pupil diameter (<xref rid="F8" ref-type="fig">Fig. 8a,b</xref>). However, because the behavioral influences of overall perceptual biases and prior relevance covaried considerably across subjects (<italic>r</italic>=0.77, <italic>p</italic>&#x0003c;10<sup>&#x02212;9</sup>), we constructed a new linear model that included two individual-difference variables that corresponded to the shared and unique variance of the two behavioral coefficients. The effects of the shared term were negative for most of the measurement window (<xref rid="F8" ref-type="fig">Fig. 8e</xref>; duration=2.2 s, <italic>p</italic>=0.01). In contrast, the unique-variance term did not show a strong relationship to average pupil traces. This result implies that subjects who had the strongest overall perceptual biases, and modulated them most according to prior relevance, tended also to have the smallest stimulus-evoked pupil responses.</p><p id="P13">To further quantify these within- and across-subject relationships between pupil diameter and task performance, we used pupil diameter to predict the subjects&#x02019; perceptual biases. Specifically, we created three normalized variables to reflect within- and across-subject variability in pupil responses at the time of peak response (1.4 s following stimulus onset) along with their multiplicative interaction. Each pupil-derived variable was included as a modulator of prediction errors in three different linear models of perceptual errors. In the simplest model, pupil-derived measures alone predicted systematic differences in perceptual biases observed in the behavioral data (<xref rid="SD1" ref-type="supplementary-material">Supplemental Fig. 3a</xref>), such that biases were: 1) larger for trials in which pupil responses were smaller than average (<italic>t</italic>-test, <italic>p</italic>&#x0003c;10<sup>&#x02212;4</sup>), 2) larger for subjects who had smaller than average pupil responses (<italic>p</italic>&#x0003c;10<sup>&#x02212;3</sup>), and 3) modulated from trial to trial more steeply for subjects with smaller overall pupil responses (<italic>p</italic>&#x0003c;0.01; <xref rid="SD1" ref-type="supplementary-material">Supplemental Fig. 3b</xref>). Consistent with these relationships, the pupil-based measures offered a substantial improvement to the base model in terms of predicting behavior (likelihood-ratio test, <italic>p</italic>&#x0003c;10<sup>&#x02212;7</sup>; <xref rid="SD1" ref-type="supplementary-material">Supplemental Fig. 3c</xref>). The pupil-based measures also offered an explanatory advantage when added to more complex models that accounted for direct fixed effects (one coefficient for all subjects) or random effects (one coefficient per subject) of relevance, reliability, and confidence reports on perceptual biases (<italic>p</italic>&#x0003c;10<sup>&#x02212;4</sup> for both models; <xref rid="SD1" ref-type="supplementary-material">Supplemental Fig. 3c</xref>). Taken together, these results imply that fluctuations in pupil diameter, particularly those mediated by stimuli and related to context relevance, can be used to determine the extent to which perception is biased towards pre-existing priors.</p></sec></sec><sec sec-type="discussion" id="S6"><title>Discussion</title><p id="P14">We used an auditory-localization task to show that the influence of prior expectations on perception is regulated rapidly and adaptively in changing environments. This work combines and extends several lines of research. The first has emphasized the role of priors on the perception of an uncertain sensory stimulus <sup><xref rid="R12" ref-type="bibr">12</xref></sup>. Many of these studies have focused on priors that are related to relatively stable properties of the environment, although several recent studies have shown that certain sensory or sensory-motor priors can be learned relatively rapidly <sup><xref rid="R9" ref-type="bibr">9</xref>,<xref rid="R20" ref-type="bibr">20</xref>&#x02013;<xref rid="R23" ref-type="bibr">23</xref></sup>. The second has shown that under a variety of conditions, individual variability in decision-making can involve differential use of priors <sup><xref rid="R24" ref-type="bibr">24</xref></sup>. The third has identified how predictions are updated and used to make decisions in dynamic environments <sup><xref rid="R10" ref-type="bibr">10</xref>,<xref rid="R25" ref-type="bibr">25</xref>,<xref rid="R26" ref-type="bibr">26</xref></sup>. The fourth has related this dynamic updating process to changes in physiological arousal <sup><xref rid="R11" ref-type="bibr">11</xref>,<xref rid="R27" ref-type="bibr">27</xref></sup>. We showed that many of these principles, including dynamic, arousal-related adjustments in predictions, apply to how priors are updated and used to guide perception.</p><p id="P15">These principles involve ongoing assessments of the relevance and reliability of priors that represent a form of statistical learning <sup><xref rid="R28" ref-type="bibr">28</xref>,<xref rid="R29" ref-type="bibr">29</xref></sup>. We quantified this learning process using two variables derived from normative theory <sup><xref rid="R17" ref-type="bibr">17</xref>,<xref rid="R30" ref-type="bibr">30</xref>&#x02013;<xref rid="R33" ref-type="bibr">33</xref></sup>. The first, which we termed prior relevance, is closely related to unexpected uncertainty and reflects the probability that a new observation is consistent with recent history <sup><xref rid="R10" ref-type="bibr">10</xref>,<xref rid="R17" ref-type="bibr">17</xref></sup>. The second, which we termed prior reliability, is a form of reducible uncertainty that reflects ambiguity, typically resulting from undersampling, about the current generative process <sup><xref rid="R32" ref-type="bibr">32</xref>,<xref rid="R33" ref-type="bibr">33</xref></sup>. Previous work showed that new information exerts the least influence on existing predictions when those predictions are the most relevant and reliable <sup><xref rid="R10" ref-type="bibr">10</xref>,<xref rid="R25" ref-type="bibr">25</xref></sup>. We showed analogous effects for perception: new sensory input exerts the least influence on perception, relative to the influence of priors (i.e., perceptual biases are largest), when the priors are the most relevant and reliable.</p><p id="P16">Both of these normative factors, scaled according to their effects on each subject&#x02019;s behavior, were reflected in modulations of arousal state as measured by pupil diameter. Prior reliability corresponded to changes in baseline pupil diameter, and prior relevance corresponded to changes in the stimulus-evoked change in pupil diameter. These modulations were similar to those that we reported previously for a predictive-inference task, but the different demands of our present task imply a broader relevance to different forms of information processing <sup><xref rid="R11" ref-type="bibr">11</xref></sup>. Specifically, our previous findings implicated a role for arousal fluctuations in adjusting bottom-up effects of new sensory input on stored cognitive representations. In contrast, our present findings implicate a role for arousal fluctuations in adjusting top-down control exerted by stored representations on the interpretation of new sensory input.</p><p id="P17">This result has broad implications for decision-making. For simple sensory-motor tasks, sequential effects of choice and response times can reflect priors inferred from recent task patterns, even when the patterns are spurious and thus the effects are detrimental to overall performance <sup><xref rid="R34" ref-type="bibr">34</xref>&#x02013;<xref rid="R36" ref-type="bibr">36</xref></sup> Our results suggest a role for stimulus-evoked arousal responses in minimizing such suboptimal biases, potentially by reducing the impact of the top-down signals that mediate them. Consistent with this idea, pupil dilations have been shown to be accompanied by reduced individual and sequential-choice biases on perceptual decision-making tasks <sup><xref rid="R37" ref-type="bibr">37</xref>,<xref rid="R38" ref-type="bibr">38</xref></sup>. For more complex tasks, top-down prior information might be used to select task-relevant feature information and thereby reduce implicit processing biases <sup><xref rid="R39" ref-type="bibr">39</xref>,<xref rid="R40" ref-type="bibr">40</xref></sup>. This effect might explain why individuals with larger evoked pupil responses tend to be more susceptible to their own implicit processing biases <sup><xref rid="R41" ref-type="bibr">41</xref>,<xref rid="R42" ref-type="bibr">42</xref></sup>. Future work should address this possibility in paradigms that combine implicit sensory biases with stimulus history-dependent priors such as those used in our task.</p><p id="P18">These results are also consistent with the idea that transient increases in arousal, in response to surprising events or other factors, may generally correspond to higher sensitivity to immediate sensory input <sup><xref rid="R43" ref-type="bibr">43</xref>,<xref rid="R44" ref-type="bibr">44</xref></sup>. In principle, this increased sensitivity could emerge from an enhancement of feed-forward processing, perhaps though an increase in neural gain <sup><xref rid="R11" ref-type="bibr">11</xref>,<xref rid="R18" ref-type="bibr">18</xref>,<xref rid="R41" ref-type="bibr">41</xref>,<xref rid="R45" ref-type="bibr">45</xref></sup>. An alternative, but not necessarily mutually exclusive, possibility supported by our results is that enhanced sensitivity to sensory input is afforded by a reduction in the effectiveness of top-down priors in regularizing, and thereby biasing, sensory percepts. Distinguishing and understanding the independent contributions of these alternatives to arousal-mediated information processing will require the development of new paradigms that can separately control the bottom-up and top-down flow of information.</p><p id="P19">We also found relationships between subjective confidence, perceptual biases, and pupil diameter. We measured confidence using a post-decision binary confidence report (high/low confidence), which previously has been linked to the sensory-driven decision variable that also governs the speed and accuracy of the perceptual decision <sup><xref rid="R46" ref-type="bibr">46</xref>&#x02013;<xref rid="R48" ref-type="bibr">48</xref></sup>. We showed that confidence is also modulated according to changes in the relevance and reliability of perceptual priors that affect perceptual errors. This modulation was also evident in pupil diameter, which reflected high confidence-report frequency even after accounting for the normative variables that also governed the perceptual biases. However, this extra effect was in the opposite direction as for the normative factors, relative to the behavioral effect: high confidence-report frequency corresponded to larger pupil diameters but stronger prior influence. This pupil effect is somewhat surprising given that pupil diameter can be enhanced under uncertain, rather than certain, conditions <sup><xref rid="R11" ref-type="bibr">11</xref>,<xref rid="R38" ref-type="bibr">38</xref>,<xref rid="R49" ref-type="bibr">49</xref>&#x02013;<xref rid="R52" ref-type="bibr">52</xref></sup> (but see <sup><xref rid="R27" ref-type="bibr">27</xref></sup>). One possible explanation for this discrepancy is that the post-decision confidence report led subjects to anticipate the increased reward or risk associated with high confidence-report trials, leading to stronger arousal responses <sup><xref rid="R51" ref-type="bibr">51</xref>,<xref rid="R53" ref-type="bibr">53</xref></sup>. This idea is supported by the time course of confidence-related pupil dilations, which had a maximal dilation immediately prior to the perceptual report. This idea also highlights the multiple, possibly interacting roles that the arousal system likely plays in even simple sensory-motor tasks like this one.</p><p id="P20">These multiple roles undoubtedly result from multiple mechanisms by which arousal affects neural information processing <sup><xref rid="R54" ref-type="bibr">54</xref></sup>. One such mechanism likely involves cortical levels of norepinephrine (NE), which is controlled via neurons in the midbrain nucleus locus coeruleus (LC) <sup><xref rid="R18" ref-type="bibr">18</xref></sup>. Firing rates of LC neurons correlate with pupil diameter over relatively short timescales, which has prompted the suggestion that pupil diameter can be used as a proxy for LC activity <sup><xref rid="R18" ref-type="bibr">18</xref>,<xref rid="R19" ref-type="bibr">19</xref>,<xref rid="R55" ref-type="bibr">55</xref>,<xref rid="R56" ref-type="bibr">56</xref></sup>. Thus, the factors in our task that corresponded to stimulus-evoked pupil dilations, such as more surprising stimuli with lower prior relevance, may also correspond to increased LC activation. This activation, in turn, would increase levels of cortical NE, which have been theorized to signal unexpected context changes and allow neural representations to reorient rapidly to meet changing contextual demands, possibly via modulations of the input/output gain of individual cortical neurons <sup><xref rid="R14" ref-type="bibr">14</xref>,<xref rid="R17" ref-type="bibr">17</xref>,<xref rid="R18" ref-type="bibr">18</xref>,<xref rid="R45" ref-type="bibr">45</xref>,<xref rid="R57" ref-type="bibr">57</xref></sup>. In contrast, slower changes in pupil diameter, such as those related to our baseline modulations, may be more closely related to levels of acetylcholine released from the basal forebrain, which has been theorized to signal expected uncertainty of task-relevant beliefs <sup><xref rid="R17" ref-type="bibr">17</xref>,<xref rid="R58" ref-type="bibr">58</xref><xref rid="R59" ref-type="bibr">59</xref></sup>. More work is needed to determine how these multiple, potentially interacting neuromodulatory systems help to regulate perception and decision-making in dynamic environments.</p></sec><sec sec-type="methods" id="S7"><title>Experimental Procedures</title><p id="P21">Human subject protocols were approved by the University of Pennsylvania Internal Review Board. 29 subjects (16 female, 13 male) participated in the study after providing informed consent. Thirty-one additional subjects consented to the study but did not meet the inclusion criterion of participating in at least three experimental sessions. Our sample size was well powered to detect effects of d&#x02019; &#x0003e; 0.6 (statistical power &#x0003e; 0.88 for d&#x02019; = 0.6) providing sufficient sensitivity in the range of previously reported behaviour-pupil relationships.</p><sec id="S8"><title>Auditory-localization task</title><p id="P22">We used an auditory-localization task in which subjects heard sounds with varying source locations that were simulated using head-related transfer functions (HRTFs) from the IRCAM database (<ext-link ext-link-type="uri" xlink:href="http://recherche.ircam.fr/equipes/salles/listen/download.html">http://recherche.ircam.fr/equipes/salles/listen/download.html</ext-link>). Each sound was a sequence of five Gaussian noise pulses bandpass filtered between 100 Hz and 15 KHz. The pulses were 50 ms each with a delay of 10 ms following each pulse, for a total stimulus duration of 300 ms. The latency for the sound to reach the ears following the command execution was ~3 ms. For each subject, we tested a number of HRTFs during the initial session by playing sound sequences that circularly traversed the entire horizontal plane in 15&#x000b0; intervals. We picked the HRTF that was reported to give the most uniformly circular percept for the sound sequence. Each subject performed 3&#x02013;6 total sessions.</p><p id="P23">Each subject completed two tasks per session. The first was a control localization task that required the subject to indicate the perceived location of simulated sound sources that were sampled independently and uniformly randomly along the frontal, horizontal plane. In each of 72 trials, the subject was required to: 1) fixate for 2.5 s on a central spot while listening to the auditory stimulus; and 2) indicate the perceived location of the sound using a mouse, which controlled a cursor that moved along a semi-circular arc on the computer screen that represented the range of possible sound-source locations (<xref rid="F1" ref-type="fig">Fig. 1</xref>). Failure to maintain fixation resulted in a warning sound and trial break. Feedback was displayed on the screen after the subject reported the perceived location.</p><p id="P24">The second task was a dynamic localization task that required the subject to report predictions, perceptions, and confidence judgments of sound-source locations that were generated from a change-point process along the same horizontal plane. For this task, the subject listened to extended sequences of sounds generated by the change-point process, with an interval of 150 ms between each sound presentation. Each sound was paired with a visual cue indicating its simulated source location on the semi-circular arc. During the presentation of these sequences, no action was required. Occasionally, however, the sequences stopped, indicating the start of a &#x0201c;probe trial&#x0201d; with the following structure (<xref rid="F1" ref-type="fig">Fig. 1c</xref>). First, the subject was required to predict the angular location of the next, upcoming probe stimulus on the arc using a mouse. Second, following the prediction, the subject was required to maintain fixation for 2.5 s on the same central spot used in the control task. The auditory probe stimulus, with no corresponding visual cue, was presented at the beginning of this fixation period. Fourth, after the fixation period ended, the subject indicated the perceived location of the probe stimulus using the mouse and the visual display. Fifth, the subject then reported confidence (high/low) on the accuracy of the perceptual report (<xref rid="F1" ref-type="fig">Fig 1</xref>). Each subject performed four blocks of the dynamic task per session, which included ~30 probe trials each. Each session lasted ~90 min, with some variability due to the self-paced nature of the prediction, perceptual report, and confidence reporting periods of the task (median [IQR] reaction times were: 1.72 [1.49&#x02013;2.35] sec for the prediction, 2.02 [1.50&#x02013;2.30] sec for the perceptual report, and 1.18 [0.94&#x02013;1.43] sec for the confidence report).</p><p id="P25">The sequence of simulated sound-source locations for the dynamic task was determined according to a process that included both irreducible variability (noise) and abrupt discontinuities (change-points). Our goal was to test if and how these manipulations, which can affect the reliability and relevance, respectively, of new information on existing predictions, also affect perceptual reports that can, in principle, use such predictions to improve the perception of ambiguous stimuli <sup><xref rid="R10" ref-type="bibr">10</xref></sup>. Source locations were sampled from a Gaussian distribution with a standard deviation (STD) that was held constant within a block of 600 trials (10&#x000b0; or 20&#x000b0; for the low- or high-noise condition, respectively) and a mean that underwent abrupt change-points with a fixed probability, or hazard rate (<italic>H</italic>), of 0.15 for each sound sample. At each change-point, the mean of the generative distribution was resampled uniformly across the sound space, such that the newly generated source locations were independent from previous ones. The sequence was interrupted for probe trials at random using a procedure that ensured: 1) a roughly even distribution of probes occurring 1&#x02013;6 sounds after a change-point (SAC); 2) that probes were separated by at least 8 sounds; and 3) the number of sounds between any two probe trials was the same, on average, regardless of the nature of the two probe trials (SAC 1&#x02013;6). Thus, on some trials the probe sound-source location was independent of the previous stimulus sequence (SAC=1). On other trials, the probe location was generated from the same distribution that produced the immediately preceding locations (SAC=2&#x02013;6).</p><p id="P26">Subjects were motivated to make accurate perceptual reports on each probe trial through an incentive system. They were instructed to report high confidence if they were confident that the true location was within a 16&#x000b0; window centered on their second (perceptual) report, and to report low confidence otherwise. A correct/incorrect high confidence report resulted in a score of (15/&#x02212;10), and a correct/incorrect low confidence resulted in a score of (5/&#x02212;3). Subjects were paid a bonus that depended on their total score.</p></sec><sec id="S9"><title>Behavioral data analysis: contrasts</title><p id="P27">To provide an intuitive understanding of how behavior was affected by particular task conditions, we sorted probe trials into twelve conditions according to the recency of the previous change-point (SAC=1&#x02013;6) and noise condition (high/low). To emphasize the effects of change-points on the behavioral reports, these analyses included data only from sequences following easily noticeable change-points, corresponding to changes in generative mean of at least twice the generative STD for SAC=1 (note that the linear model described below was used to analyze the full data sets, including all change-points). Perceptual and prediction errors were computed by subtracting reported percepts and predictions from the true (simulated) sound source location for each trial. For each condition, the STD of prediction and estimation errors was used as a metric of average absolute error magnitude.</p><p id="P28">To quantify how prediction errors, estimation errors, and average confidence reports depended on specific task conditions, we performed four orthogonal linear contrasts over our twelve task conditions. Each contrast was computed by multiplying a weight matrix by the measured prediction errors, estimation errors, or average confidence reports, aggregated according to the task conditions for a single subject. Weight matrices were mean centered and chosen to identify: 1) differences between change-point and non-change-point trials (CP); 2) linear increases with increases in the number of sounds experienced (Exp) following a change-point, from SAC=2 to SAC=6, in the high-noise condition (Exp<sub>high</sub>); 3) comparable linear increases in the low-noise condition (Exp<sub>low</sub>); and 4) differences between the high- and low-noise conditions (Noise). Thus, the contrasts provided a per-subject measure of how much each behavioral measurement was modified according to these factors. For <xref rid="F3" ref-type="fig">Figs. 3</xref>&#x02013;<xref rid="F5" ref-type="fig">5</xref>, we considered only sound sequences following relatively large change-points, corresponding to at least twice the generative STD. Contrasts were normalized for presentation in <xref rid="F3" ref-type="fig">Figs. 3</xref> and <xref rid="F4" ref-type="fig">4</xref> by dividing the contrast value for each subject by the standard deviation of that contrast across all subjects. This procedure allowed all contrasts to be meaningfully displayed on the same set of axes.</p></sec><sec id="S10"><title>Behavioral data analysis: perceptual bias</title><p id="P29">To quantify the influence of the prior on the perceptual report, we measured the slope of the best-fit line to the relationship between prediction errors (prediction&#x02013;true location) and perceptual errors (percept&#x02013;true location) for the given task condition. Slopes close to one indicate a high perceptual bias, and slopes close to zero indicate low perceptual bias. To measure how the perceptual bias evolved as a function of the number of sounds after a change-point (SAC), we used the following linear model and included only data from sequences following noticeable change-points (jumps of at least twice the generative STD): 
<disp-formula id="FD1"><label>[1]</label><mml:math id="M2" display="block" overflow="scroll"><mml:mrow><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mi mathvariant="italic">ERR</mml:mi><mml:mi mathvariant="italic">percp</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>&#x003b2;</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003b2;</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msubsup><mml:mi mathvariant="italic">ERR</mml:mi><mml:mrow><mml:mi mathvariant="italic">pred</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi mathvariant="italic">high</mml:mi></mml:msubsup><mml:mo>+</mml:mo><mml:mo>&#x022ef;</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003b2;</mml:mi><mml:mn>6</mml:mn></mml:msub><mml:msubsup><mml:mi mathvariant="italic">ERR</mml:mi><mml:mrow><mml:mi mathvariant="italic">pred</mml:mi><mml:mo>,</mml:mo><mml:mn>6</mml:mn></mml:mrow><mml:mi mathvariant="italic">high</mml:mi></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003b2;</mml:mi><mml:mn>7</mml:mn></mml:msub><mml:msubsup><mml:mi mathvariant="italic">ERR</mml:mi><mml:mrow><mml:mi mathvariant="italic">pred</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi mathvariant="italic">low</mml:mi></mml:msubsup><mml:mo>+</mml:mo><mml:mo>&#x022ef;</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003b2;</mml:mi><mml:mn>12</mml:mn></mml:msub><mml:msubsup><mml:mi mathvariant="italic">ERR</mml:mi><mml:mrow><mml:mi mathvariant="italic">pred</mml:mi><mml:mo>,</mml:mo><mml:mn>6</mml:mn></mml:mrow><mml:mi mathvariant="italic">low</mml:mi></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003b2;</mml:mi><mml:mn>13</mml:mn></mml:msub><mml:msub><mml:mi mathvariant="italic">Bias</mml:mi><mml:mi mathvariant="italic">spatial</mml:mi></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula> where <italic>ERR<sub>percp</sub></italic> is the perceptual error and 
<inline-formula><mml:math id="M3" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi mathvariant="italic">ERR</mml:mi><mml:mrow><mml:mi mathvariant="italic">pred</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi mathvariant="italic">high</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> is the prediction error on change-point trials (SAC=1) in the high-noise condition, and so on. The last term, <italic>Bias<sub>spatial</sub></italic>, captures the slight bias in the perceptual reports towards center of the screen.</p></sec><sec id="S11"><title>Behavioral data analysis: theoretical benchmarks</title><p id="P30">The theoretically expected overall perceptual-error STD per subject (abscissa in <xref rid="F2" ref-type="fig">Fig. 2i</xref>) was computed from an optimal, reliability-weighted combination of prior and sensory information: 
<inline-formula><mml:math id="M4" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">&#x003c3;</mml:mi><mml:mi mathvariant="italic">theoretical</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi mathvariant="normal">&#x003c3;</mml:mi><mml:mi mathvariant="italic">predictions</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi mathvariant="normal">&#x003c3;</mml:mi><mml:mi mathvariant="italic">sensory</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>. The theoretically expected perceptual-error STD per subject (diamonds in <xref rid="F3" ref-type="fig">Fig. 3c,d</xref>), given their corresponding predictions for each SAC condition, was computed using 
<inline-formula><mml:math id="M5" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi mathvariant="normal">&#x003c3;</mml:mi><mml:mi mathvariant="italic">theoretical</mml:mi><mml:mi mathvariant="italic">SAC</mml:mi></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi mathvariant="normal">&#x003c3;</mml:mi><mml:mi mathvariant="italic">predictions</mml:mi><mml:mi mathvariant="italic">SAC</mml:mi></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mi mathvariant="normal">&#x003c3;</mml:mi><mml:mi mathvariant="italic">sensory</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>. The theoretically expected frequency of high-confidence reports (diamonds in <xref rid="F3" ref-type="fig">Fig. 3e,f</xref>) was computed as the probability mass contained in a 16&#x000b0; window centered at the mean of a Gaussian with a STD of the theoretically expected perceptual errors, 
<inline-formula><mml:math id="M6" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">&#x003c3;</mml:mi><mml:mi mathvariant="italic">theoretical</mml:mi><mml:mi mathvariant="italic">SAC</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>. Thus, the proportion of expected high-confidence reports increased with narrower perceptual error distributions. The theoretically expected perceptual bias per subject (diamonds in <xref rid="F4" ref-type="fig">Fig. 4d,e</xref>) was computed as 
<inline-formula><mml:math id="M7" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">&#x003c3;</mml:mi><mml:mi mathvariant="italic">sensory</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="true">/</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi mathvariant="normal">&#x003c3;</mml:mi><mml:mi mathvariant="italic">predictions</mml:mi><mml:mi mathvariant="italic">SAC</mml:mi></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mi mathvariant="normal">&#x003c3;</mml:mi><mml:mi mathvariant="italic">sensory</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>. In all of the above, <italic>&#x003c3;<sub>predictions</sub></italic> is the STD of prediction errors on non-change-point trials, 
<inline-formula><mml:math id="M8" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">&#x003c3;</mml:mi><mml:mi mathvariant="italic">predictions</mml:mi><mml:mi mathvariant="italic">SAC</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> is the STD of prediction errors for the specified number of sounds after a change-point, and <italic>&#x003c3;<sub>sensory</sub></italic> is the STD of perceptual errors on the control task, computed per subject.</p></sec><sec id="S12"><title>Behavioral data analysis: normative model</title><p id="P31">Auditory localization in a dynamic environment can be posed as a perceptual inference problem with the goal of inferring the location of the sound source on trial <italic>t</italic> (<italic>X<sub>t</sub></italic>) according to a noisy internal sensory representation of that sound source (<italic>&#x003bb;<sub>t</sub></italic>) and the history of previously experienced sound sources (<italic>X</italic><sub>1:</sub><italic><sub>t</sub></italic><sub>&#x02212;1</sub>). This problem can be simplified by exploiting the conditional independencies in the Markov change-point process through which sound sources are selected (see <xref rid="SD1" ref-type="supplementary-material">Supplementary Fig. 1</xref>). In particular, the sound sources locations on the current trial (<italic>X<sub>t</sub></italic>) are independent of those on previous trials (<italic>X</italic><sub>1:</sub><italic><sub>t</sub></italic><sub>&#x02212;1</sub>) conditioned on the mean of the generative distribution on the current trial (<italic>&#x003bc;<sub>t</sub></italic>). In turn, the mean of the generative distribution on the current trial (<italic>&#x003bc;<sub>t</sub></italic>) is also independent of previous observations conditioned on: 1) the mean of the generative distribution on the previous trial (<italic>&#x003bc;<sub>t</sub></italic><sub>&#x02212;1</sub>), and 2) a latent change-point variable that determines whether the mean is resampled on the current trial (<italic>s<sub>t</sub></italic>). Applying Bayes rule to invert the generative graph in <xref rid="SD1" ref-type="supplementary-material">Supplementary Fig. 1</xref> yields the following inference equation: 
<disp-formula id="FD2"><label>[2]</label><mml:math id="M9" display="block" overflow="scroll"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>&#x02223;</mml:mo><mml:msub><mml:mi>&#x003bb;</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle scriptlevel="1"><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>&#x003bb;</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>&#x02223;</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi mathvariant="normal">&#x02211;</mml:mi><mml:msub><mml:mi>&#x003bc;</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:msub><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>&#x02223;</mml:mo><mml:msub><mml:mi>&#x003bc;</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi mathvariant="normal">&#x02211;</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:msub><mml:msub><mml:mi mathvariant="normal">&#x02211;</mml:mi><mml:msub><mml:mi>&#x003bc;</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:msub><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>&#x003bc;</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>&#x02223;</mml:mo><mml:msub><mml:mi>&#x003bc;</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>&#x003bc;</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&#x02223;</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="normal">&#x02211;</mml:mi><mml:msub><mml:mi>X</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:msub><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>&#x003bb;</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>&#x02223;</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:math></disp-formula> where the likelihood <italic>P</italic>(<italic>&#x003bb;<sub>t</sub></italic>|<italic>X<sub>t</sub></italic>) reflects the conditional distribution of internal representations across true sound source locations; <italic>P</italic>(<italic>X<sub>t</sub></italic>|<italic>&#x003bc;<sub>t</sub></italic>) reflects the conditional probability of a sound source location being generated from a particular generative mean; <italic>P</italic>(<italic>&#x003bc;<sub>t</sub></italic>|<italic>&#x003bc;<sub>t</sub></italic><sub>&#x02212;1,</sub> s<sub>t</sub>) reflects the process through which means are resampled on change-point (s<sub>t</sub> =1) trials; and <italic>P</italic>(<italic>s<sub>t</sub></italic>) is the hazard rate (<italic>H</italic>), which was fixed to 0.15 for the task and all simulations. The likelihood <italic>P</italic>(<italic>&#x003bb;</italic><sub>t</sub>|X<sub>t</sub>) was modeled as a normal distribution centered on X<sub>t</sub> with a variance that was fixed for each subject to the variance of perceptual reports made by that subject on the control task (
<inline-formula><mml:math id="M10" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">&#x003c3;</mml:mi><mml:mtext>sensory</mml:mtext><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>). <italic>P</italic>(<italic>&#x003bc;<sub>t</sub></italic><sub>&#x02212;1</sub>|X<sub>1:t&#x02212;1</sub> is the distribution over possible generative means, which can be updated recursively. Although exact Bayesian solutions to this recursive problem exist <sup><xref rid="R13" ref-type="bibr">13</xref>,<xref rid="R30" ref-type="bibr">30</xref></sup>, we use a normal approximation to the Bayesian mixture distribution with a mean (<italic>&#x003bc;&#x00302;</italic>) and variance (<italic>&#x003c3;&#x00302;</italic><sup>2</sup>) that capture the key dynamics of normative inference and offers better descriptions of human behaviour <sup><xref rid="R10" ref-type="bibr">10</xref></sup>. As in previous work, predictions made using this approximation were more accurate than subject predictions. To account for this discrepancy, we created a subjective prediction <italic>&#x003bc;&#x00302;<sub>subj</sub></italic> by sampling a random normal variable with mean equal to <italic>&#x003bc;&#x00302;</italic> and a variance that was incremented on each trial according to the difference in variance of subject and normative prediction errors: 
<disp-formula id="FD3"><label>[3]</label><mml:math id="M11" display="block" overflow="scroll"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi mathvariant="normal">&#x003c3;</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi mathvariant="italic">subj</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>&#x003c3;</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mtext>Var</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">X</mml:mi><mml:mo>-</mml:mo><mml:mtext>subject</mml:mtext><mml:mspace width="0.16667em"/><mml:mtext>predictions</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mo>-</mml:mo><mml:mtext>Var</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">X</mml:mi><mml:mo>-</mml:mo><mml:mover accent="true"><mml:mi>&#x003bc;</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="P32">Thus, the overall model incorporates the prospect of sub-optimal predictions about the sound-source location but implements Bayesian optimal combination of these predictions with incoming sensory information according to environmental dynamics.</p><p id="P33">Perceptions and predictions from the normative model were simulated by sampling internal representations (<italic>&#x003bb;<sub>t</sub></italic>) and subjective predictions (<italic>&#x003bc;&#x00302;<sub>subj</sub></italic>) for each trial according to the actual sequence of sound source locations experienced. Descriptive statistics for model simulations were averaged across 100 such simulated runs.</p><p id="P34">In addition to simulating behavioral data, the normative model also allowed us to extract latent variables that guide normative adjustments in perceptual bias. In particular, the model adjusts bias towards prior expectations in accordance with the relevance and reliability of those expectations. The relevance of prior expectations (<italic>&#x003c0;<sub>t</sub></italic>) is, in our generative framework, equal to the probability that a change-point did not occur on this trial given all previous data. This probability was computed on each trial by marginalizing <xref rid="FD2" ref-type="disp-formula">Eq. 2</xref> over all dimensions other than <italic>s</italic>. The impact of normative priors also depends critically on their reliability relative to that of the likelihood distribution capturing the noisy internal sensory representation (<italic>&#x003bb;<sub>t</sub></italic>): 
<disp-formula id="FD4"><label>[4]</label><mml:math id="M12" display="block" overflow="scroll"><mml:mrow><mml:mtext>prior</mml:mtext><mml:mspace width="0.16667em"/><mml:mtext>reliability</mml:mtext><mml:mo>:</mml:mo><mml:msub><mml:mi mathvariant="normal">&#x003c4;</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:msubsup><mml:mi mathvariant="normal">&#x003c3;</mml:mi><mml:mtext>sensory</mml:mtext><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">&#x003c3;</mml:mi><mml:mtext>sensory</mml:mtext><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi mathvariant="normal">&#x003c3;</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mtext>subj</mml:mtext><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi mathvariant="normal">&#x003c3;</mml:mi><mml:mtext>noise</mml:mtext><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula> where &#x003c4;<sub>t</sub> is prior reliability, 
<inline-formula><mml:math id="M13" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">&#x003c3;</mml:mi><mml:mtext>sensory</mml:mtext><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> is the variance of perceptual reports made by that subject on the control task, 
<inline-formula><mml:math id="M14" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi mathvariant="normal">&#x003c3;</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mtext>subj</mml:mtext><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> is the variance on subjective assessments of the underlying mean, and 
<inline-formula><mml:math id="M15" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">&#x003c3;</mml:mi><mml:mtext>noise</mml:mtext><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> is the expected variance of sound source locations about that mean. The sum of the latter two terms reflects the total variance on the model&#x02019;s predictive distribution over possible sound locations. To ensure that these latent variables best reflected circumstances experienced by the subject, we fixed the model predictions (<italic>&#x003bc;&#x00302;<sub>subj</sub></italic>) to the actual subject predictions from each trial and computed each measure as the expected value across all possible values of &#x003bb;<sub>t</sub> using a grid-point approximation.</p></sec><sec id="S13"><title>Behavioral data analysis: Linear model of perceptual bias</title><p id="P35">To provide a more complete description of how behavioral data from all conditions, including all generative change-point and non-change-point trials, depended on both normative and non-normative factors, we fit the following linear model to data from all trials in each session: 
<disp-formula id="FD5"><label>[5]</label><mml:math id="M16" display="block" overflow="scroll"><mml:mrow><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mi mathvariant="italic">ERR</mml:mi><mml:mi mathvariant="italic">percp</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>&#x003b2;</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003b2;</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi mathvariant="italic">ERR</mml:mi><mml:mi mathvariant="italic">pred</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003b2;</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:msub><mml:mi mathvariant="italic">ERR</mml:mi><mml:mi mathvariant="italic">pred</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x000b7;</mml:mo><mml:msub><mml:mi>&#x003c0;</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003b2;</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:msub><mml:mi mathvariant="italic">ERR</mml:mi><mml:mi mathvariant="italic">pred</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x000b7;</mml:mo><mml:msub><mml:mi>&#x003c4;</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003b2;</mml:mi><mml:mn>4</mml:mn></mml:msub><mml:msub><mml:mi mathvariant="italic">ERR</mml:mi><mml:mi mathvariant="italic">pred</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x000b7;</mml:mo><mml:mi mathvariant="italic">bet</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003b2;</mml:mi><mml:mn>5</mml:mn></mml:msub><mml:msub><mml:mi mathvariant="italic">Bias</mml:mi><mml:mi mathvariant="italic">center</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003b2;</mml:mi><mml:mn>6</mml:mn></mml:msub><mml:msub><mml:mi mathvariant="italic">Bias</mml:mi><mml:mi mathvariant="italic">spatial</mml:mi></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula> where <italic>&#x003b2;</italic><sub>1</sub> describes the overall prior bias; <italic>&#x003b2;</italic><sub>2</sub> and <italic>&#x003b2;</italic><sub>2</sub> describe the extent to which the overall bias is dynamically modulated by the prior relevance and reliability, respectively (see above); <italic>&#x003b2;</italic><sub>4</sub> describes the interaction of prior bias with confidence report (a binary variable); <italic>&#x003b2;</italic><sub>5</sub> describes the bias towards the center of the screen; and <italic>&#x003b2;</italic><sub>6</sub> captures the angular spatial bias (mean perceptual error at the given angle) measured in the control task. Residuals from the model fit were signed according to the prediction error on each trial to create a residual bias term for use in pupil analysis.</p></sec><sec id="S14"><title>Pupil measurements</title><p id="P36">Pupil diameter was sampled from both eyes at 60 Hz using an infrared eye-tracker built into the monitor (Tobii T60-XL). Pupil analyses used the mean value from the two eyes at each time point measured during fixation. We excluded from further analyses trials with blinks, which we identified using a custom blink-detection routine on the basis of missing pupil diameter measurements and/or vertical and horizontal eye position that deviated from fixation for at least 10 contiguous samples (median [IQR] percentage of excluded trials across sessions = 5.54 [3.16&#x02013;9.16]%). For the remaining trials with &#x0003c;10 missing contiguous pupil samples, we linearly interpolate the data before low-pass filtering. Low-pass filtering was done using a Butterworth filter with a cut-off frequency of 4 Hz. These filtered measurements were then z-scored in each session. We also removed a linear trend in the average pupil diameter over the whole session to account for any slow drift. The pupil baseline for each probe trial was defined as the mean of the first three samples immediately preceding the measurement period for that probe trial.</p></sec><sec id="S15"><title>Linear model relating pupil diameter to behavioral parameters</title><p id="P37">To measure how the variables driving behavior were encoded in pupil diameter, we used the following linear model to explain the fluctuations in: 1) the baseline pupil diameter, and 2) stimulus-evoked pupil response across the 2.5 s following the auditory stimulus: 
<disp-formula id="FD6"><label>[6]</label><mml:math id="M17" display="block" overflow="scroll"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mi mathvariant="italic">Pupil</mml:mi><mml:mspace width="0.16667em"/><mml:mi mathvariant="italic">diameter</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>&#x003b2;</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi>&#x003c0;</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003b2;</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:msub><mml:mi>&#x003c4;</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003b2;</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mi>B</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003b2;</mml:mi><mml:mn>4</mml:mn></mml:msub><mml:msub><mml:mi mathvariant="italic">Bias</mml:mi><mml:mi mathvariant="italic">residual</mml:mi></mml:msub><mml:mo>+</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>&#x003b2;</mml:mi><mml:mn>5</mml:mn></mml:msub><mml:mi mathvariant="italic">Previous</mml:mi><mml:mspace width="0.16667em"/><mml:mi mathvariant="italic">baseline</mml:mi><mml:mspace width="0.16667em"/><mml:mi mathvariant="italic">diameter</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003b2;</mml:mi><mml:mn>6</mml:mn></mml:msub><mml:mi mathvariant="italic">Time</mml:mi><mml:mspace width="0.16667em"/><mml:mi mathvariant="italic">since</mml:mi><mml:mspace width="0.16667em"/><mml:mi mathvariant="italic">Previousp</mml:mi><mml:mspace width="0.16667em"/><mml:mi mathvariant="italic">probe</mml:mi><mml:mo>+</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>&#x003b2;</mml:mi><mml:mrow><mml:mn>7</mml:mn><mml:mo>-</mml:mo><mml:mn>9</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="italic">low</mml:mi><mml:mspace width="0.16667em"/><mml:mi mathvariant="italic">freq</mml:mi><mml:mo>.</mml:mo><mml:mi mathvariant="italic">terms</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula> where <italic>&#x003c4;<sub>t</sub></italic> and <italic>&#x003c0;<sub>t</sub></italic> are the reliability and relevance, respectively; &#x003b2;<sub>1&#x02013;4</sub> capture relationships between pupil diameter and the computational and behavioral variables of interest; &#x003b2;<sub>5&#x02013;6</sub> capture persisting fluctuations in pupil diameter that are attributable to the previous trial; and &#x003b2;<sub>7&#x02013;9</sub> includes a set of three low-frequency cosine components for each session that capture task-irrelevant variability due to slow modulations or session-based differences in pupil diameter. The exact form of the cosine components was (cos(<italic>&#x003c0;</italic> &#x000b7; <italic>k</italic> (2<italic>n</italic> &#x02212; 1)/2<italic>N</italic>)), where <italic>k=0,1,2; n</italic> is the trial number within the session; and <italic>N</italic> is the total number of trials in the session. When this model was fit to evoked pupil responses, an additional nuisance variable was added to the explanatory matrix that accounted for trial-by-trial differences in baseline diameter.</p><p id="P38">Significance testing for evoked pupil coefficients was done through cluster-based permutation testing to account for multiple comparisons over time. In short, <italic>t</italic>-tests were performed on each set of coefficient values across subjects separately for each time point. Cluster size was determined according to the number of contiguous time points for which this <italic>t</italic>-test yielded <italic>p</italic>&#x0003c;0.05. Cluster corrected <italic>p</italic>-values were determined by comparing cluster sizes attained in this way to those from a permutation distribution of maximal cluster sizes <sup><xref rid="R60" ref-type="bibr">60</xref></sup>.</p></sec><sec id="S16"><title>Pupil-predicted perceptual bias</title><p id="P39">Trial-by-trial pupil measurements were extracted for the time of peak pupil response (1.4 seconds) from the behavioral model. Trial-by-trial measurements from each subject were regressed onto a set of nuisance variables that included explanatory variables <italic>&#x003b2;</italic><sub>5+</sub> from <xref rid="FD6" ref-type="disp-formula">Eq. 6</xref> to remove variance attributable to potentially confounding factors. Residual pupil measurements were concatenated across subjects and then divided into two separate variables: one variable accounted for average measurements for each subject and one that reflected normalized deviations from the average measurement within each subject. An additional term was created through the multiplicative interaction of each subject&#x02019;s mean pupil response and pupil-response variability, to account for the possibility that individual differences in the overall arousal response modulate the extent to which trial-to-trial fluctuations in arousal modulate perceptual bias. The three resulting variable arrays were z-scored and multiplied by trial-by-trial prediction errors to create a predictor matrix. Trial-by-trial perceptual errors were regressed onto three separate models with and without the inclusion of the pupil predictor matrix: 1) a null model including an intercept term and a prediction error term to capture fixed effects of perceptual bias across all subjects as well as the spatial bias terms described above [NE]; 2) a fixed-effects model that also included interaction terms accounting for modulation of perceptual bias by prior relevance and reliability the subjects&#x02019; confidence report [FE]; and 3) a random-effects model that included all terms in model 2 separately for each subject [RE]. Since the random-effects model used dummy variables to account for individual differences in perceptual bias, the pupil predictor matrix included only within-subject variability and thus only one additional parameter rather than three. The marginal benefit of pupil-predictor terms was evaluated through likelihood-ratio tests (evaluating the additional explanatory power offered by pupil predictors) and quantified using AIC, a likelihood-based measure of goodness-of-fit that applies a penalty for each model parameter.</p></sec></sec><sec sec-type="supplementary-material" id="S17"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>1</label><media xlink:href="NIHMS865461-supplement-1.pdf" orientation="portrait" xlink:type="simple" id="d36e2343" position="anchor"/></supplementary-material></sec></body><back><ack id="S18"><p>We thank Ana-Andreea Stoica and Naim Kabir for aiding in data collection. We thank Long Ding and Takahiro Doi for helpful comments. This work was funded by NIH grants F32 MH102009 (MRN) and R01 EY015260 and NSF 1533623 (JIG). The funders had no role in study design, data collection and analysis, decision to publish or preparation of the manuscript.</p></ack><fn-group><fn id="FN3" fn-type="con"><p><bold>Author Contributions</bold></p><p>All authors designed the experiment and analyses and wrote the manuscript, KK collected the data, and KK and MRN analysed the data.</p></fn><fn fn-type="COI-statement" id="FN4"><p><bold>Competing Interests</bold></p><p>None of the authors have any competing interests to report, financial or otherwise.</p></fn><fn id="FN5"><p><bold>Data availability</bold></p><p>The data that support the findings of this study are available from the authors upon request. Matlab code for all models and analysis is available at: <ext-link ext-link-type="uri" xlink:href="https://github.com/TheGoldLab/Projects/KrishnamurthyNassarEtAl2017">https://github.com/TheGoldLab/Projects/KrishnamurthyNassarEtAl2017</ext-link>.</p></fn></fn-group><ref-list><ref id="R1"><label>1</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bar</surname><given-names>M</given-names></name></person-group><article-title>Visual objects in context</article-title><source>Nature Reviews Neuroscience</source><volume>5</volume><fpage>617</fpage><lpage>629</lpage><year>2004</year><pub-id pub-id-type="pmid">15263892</pub-id></element-citation></ref><ref id="R2"><label>2</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Edwards</surname><given-names>W</given-names></name></person-group><article-title>Optimal strategies for seeking information: Models for statistics, choice reaction times, and human information processing</article-title><source>Journal of Mathematical Psychology</source><year>1965</year></element-citation></ref><ref id="R3"><label>3</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Link</surname><given-names>SW</given-names></name><name><surname>Heath</surname><given-names>RA</given-names></name></person-group><article-title>A sequential theory of psychological discrimination</article-title><source>Psychometrika</source><year>1975</year></element-citation></ref><ref id="R4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maddox</surname><given-names>WT</given-names></name><name><surname>Bohil</surname><given-names>CJ</given-names></name></person-group><article-title>Base-rate and payoff effects in multidimensional perceptual categorization</article-title><source>J Exp Psychol Learn Mem Cogn</source><volume>24</volume><fpage>1459</fpage><lpage>1482</lpage><year>1998</year><pub-id pub-id-type="pmid">9835061</pub-id></element-citation></ref><ref id="R5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seri&#x000e8;s</surname><given-names>P</given-names></name></person-group><source>Learning what to expect (in visual perception)</source><fpage>1</fpage><lpage>14</lpage><year>2013</year><pub-id pub-id-type="doi">10.3389/fnhum.2013.00668/abstract</pub-id></element-citation></ref><ref id="R6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Summerfield</surname><given-names>C</given-names></name><name><surname>Egner</surname><given-names>T</given-names></name></person-group><article-title>Expectation (and attention) in visual cognition</article-title><source>Trends in Cognitive Sciences</source><volume>13</volume><fpage>403</fpage><lpage>409</lpage><year>2009</year><pub-id pub-id-type="pmid">19716752</pub-id></element-citation></ref><ref id="R7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischer</surname><given-names>BJ</given-names></name><name><surname>Pe&#x000f1;a</surname><given-names>JL</given-names></name></person-group><article-title>Owl&#x02019;s behavior and neural representation predicted by Bayesian inference</article-title><source>Nature Publishing Group</source><volume>14</volume><fpage>1061</fpage><lpage>1066</lpage><year>2011</year></element-citation></ref><ref id="R8"><label>8</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knill</surname><given-names>DC</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><article-title>The Bayesian brain: the role of uncertainty in neural coding and computation</article-title><source>Trends in Neurosciences</source><volume>27</volume><fpage>712</fpage><lpage>719</lpage><year>2004</year><pub-id pub-id-type="pmid">15541511</pub-id></element-citation></ref><ref id="R9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stocker</surname><given-names>AA</given-names></name><name><surname>Simoncelli</surname><given-names>EP</given-names></name></person-group><article-title>Noise characteristics and prior expectations in human visual speed perception</article-title><source>Nature Neuroscience</source><volume>9</volume><fpage>578</fpage><lpage>585</lpage><year>2006</year><pub-id pub-id-type="pmid">16547513</pub-id></element-citation></ref><ref id="R10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Heasly</surname><given-names>B</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><article-title>An approximately Bayesian delta-rule model explains the dynamics of belief updating in a changing environment</article-title><source>Journal of Neuroscience</source><volume>30</volume><fpage>12366</fpage><lpage>12378</lpage><year>2010</year><pub-id pub-id-type="pmid">20844132</pub-id></element-citation></ref><ref id="R11"><label>11</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nassar</surname><given-names>MR</given-names></name><etal/></person-group><article-title>Rational regulation of learning dynamics by pupil-linked arousal systems</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>1040</fpage><lpage>1046</lpage><year>2012</year><pub-id pub-id-type="pmid">22660479</pub-id></element-citation></ref><ref id="R12"><label>12</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Knill</surname><given-names>DC</given-names></name><name><surname>Richards</surname><given-names>W</given-names></name></person-group><source>Perception as Bayesian Inference</source><publisher-name>Cambridge University Press</publisher-name><year>1996</year></element-citation></ref><ref id="R13"><label>13</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><article-title>Bayesian online learning of the hazard rate in change-point problems</article-title><source>Neural Comput</source><volume>22</volume><fpage>2452</fpage><lpage>2476</lpage><year>2010</year><pub-id pub-id-type="pmid">20569174</pub-id></element-citation></ref><ref id="R14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bouret</surname><given-names>S</given-names></name><name><surname>Sara</surname><given-names>SJ</given-names></name></person-group><article-title>Network reset: a simplified overarching theory of locus coeruleus noradrenaline function</article-title><source>Trends in Neurosciences</source><volume>28</volume><fpage>574</fpage><lpage>582</lpage><year>2005</year><pub-id pub-id-type="pmid">16165227</pub-id></element-citation></ref><ref id="R15"><label>15</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ullsperger</surname><given-names>M</given-names></name><name><surname>Harsay</surname><given-names>HA</given-names></name><name><surname>Wessel</surname><given-names>JR</given-names></name><name><surname>Ridderinkhof</surname><given-names>KR</given-names></name></person-group><article-title>Conscious perception of errors and its relation to the anterior insula</article-title><source>Brain Struct Funct</source><volume>214</volume><fpage>629</fpage><lpage>643</lpage><year>2010</year><pub-id pub-id-type="pmid">20512371</pub-id></element-citation></ref><ref id="R16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harley</surname><given-names>CW</given-names></name></person-group><article-title>Norepinephrine and the dentate gyrus</article-title><source>Prog Brain Res</source><volume>163</volume><fpage>299</fpage><lpage>318</lpage><year>2007</year><pub-id pub-id-type="pmid">17765726</pub-id></element-citation></ref><ref id="R17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>AJ</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><article-title>Uncertainty, neuromodulation, and attention</article-title><source>Neuron</source><volume>46</volume><fpage>681</fpage><lpage>692</lpage><year>2005</year><pub-id pub-id-type="pmid">15944135</pub-id></element-citation></ref><ref id="R18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aston-Jones</surname><given-names>G</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><article-title>An integrative theory of locus coeruleus-norepinephrine function: adaptive gain and optimal performance</article-title><source>Annu Rev Neurosci</source><volume>28</volume><fpage>403</fpage><lpage>450</lpage><year>2005</year><pub-id pub-id-type="pmid">16022602</pub-id></element-citation></ref><ref id="R19"><label>19</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Joshi</surname><given-names>S</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Kalwani</surname><given-names>RM</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><article-title>Relationships between Pupil Diameter and Neuronal Activity in the Locus Coeruleus, Colliculi, and Cingulate Cortex</article-title><source>Neuron</source><volume>89</volume><fpage>221</fpage><lpage>234</lpage><year>2016</year><pub-id pub-id-type="pmid">26711118</pub-id></element-citation></ref><ref id="R20"><label>20</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adams</surname><given-names>WJ</given-names></name><name><surname>Graf</surname><given-names>EW</given-names></name><name><surname>Ernst</surname><given-names>MO</given-names></name></person-group><article-title>Experience can change the &#x02018;light-from-above&#x02019; prior</article-title><source>Nature Neuroscience</source><volume>7</volume><fpage>1057</fpage><lpage>1058</lpage><year>2004</year><pub-id pub-id-type="pmid">15361877</pub-id></element-citation></ref><ref id="R21"><label>21</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berniker</surname><given-names>M</given-names></name><name><surname>Voss</surname><given-names>M</given-names></name><name><surname>Kording</surname><given-names>K</given-names></name></person-group><article-title>Learning priors for Bayesian computations in the nervous system</article-title><source>PLoS ONE</source><year>2010</year><pub-id pub-id-type="doi">10.1371/journal.pone.0012686.g001</pub-id></element-citation></ref><ref id="R22"><label>22</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burge</surname><given-names>J</given-names></name><name><surname>Ernst</surname><given-names>MO</given-names></name><name><surname>Banks</surname><given-names>MS</given-names></name></person-group><article-title>The statistical determinants of adaptation rate in human reaching</article-title><source>J Vis</source><volume>8</volume><fpage>20</fpage><lpage>20</lpage><year>2008</year></element-citation></ref><ref id="R23"><label>23</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tassinari</surname><given-names>H</given-names></name><name><surname>Hudson</surname><given-names>TE</given-names></name><name><surname>Landy</surname><given-names>MS</given-names></name></person-group><article-title>Combining Priors and Noisy Visual Cues in a Rapid Pointing Task</article-title><source>Journal of Neuroscience</source><volume>26</volume><fpage>10154</fpage><lpage>10163</lpage><year>2006</year><pub-id pub-id-type="pmid">17021171</pub-id></element-citation></ref><ref id="R24"><label>24</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stanovich</surname><given-names>KE</given-names></name><name><surname>West</surname><given-names>RF</given-names></name></person-group><article-title>Individual differences in reasoning: implications for the rationality debate?</article-title><source>Behav Brain Sci</source><volume>23</volume><fpage>645</fpage><lpage>65</lpage><comment>discussion 665&#x02013;726</comment><year>2000</year><pub-id pub-id-type="pmid">11301544</pub-id></element-citation></ref><ref id="R25"><label>25</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Woolrich</surname><given-names>MW</given-names></name><name><surname>Walton</surname><given-names>ME</given-names></name><name><surname>Rushworth</surname><given-names>MFS</given-names></name></person-group><article-title>Learning the value of information in an uncertain world</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>1214</fpage><lpage>1221</lpage><year>2007</year><pub-id pub-id-type="pmid">17676057</pub-id></element-citation></ref><ref id="R26"><label>26</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Nassar</surname><given-names>MR</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><article-title>A mixture of delta-rules approximation to bayesian inference in change-point problems</article-title><source>PLoS Comput Biol</source><volume>9</volume><fpage>e1003150</fpage><year>2013</year><pub-id pub-id-type="pmid">23935472</pub-id></element-citation></ref><ref id="R27"><label>27</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Preuschoff</surname><given-names>K</given-names></name></person-group><article-title>Pupil dilation signals surprise: evidence for noradrenaline&#x02019;s role in decision making</article-title><fpage>1</fpage><lpage>12</lpage><year>2011</year><pub-id pub-id-type="doi">10.3389/fnins.2011.00115/abstract</pub-id></element-citation></ref><ref id="R28"><label>28</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tenenbaum</surname><given-names>JB</given-names></name><name><surname>Kemp</surname><given-names>C</given-names></name><name><surname>Griffiths</surname><given-names>TL</given-names></name></person-group><article-title>How to grow a mind: Statistics, structure, and abstraction</article-title><source>Science</source><year>2011</year></element-citation></ref><ref id="R29"><label>29</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Vapnik</surname><given-names>V</given-names></name></person-group><source>The Nature of Statistical Learning Theory</source><publisher-name>Springer Science &#x00026; Business Media</publisher-name><year>2013</year></element-citation></ref><ref id="R30"><label>30</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Adams</surname><given-names>RP</given-names></name><name><surname>MacKay</surname><given-names>D</given-names></name></person-group><source>Bayesian Online Changepoint Detection</source><year>2007</year></element-citation></ref><ref id="R31"><label>31</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathys</surname><given-names>C</given-names></name></person-group><source>A Bayesian foundation for individual learning under uncertainty</source><fpage>1</fpage><lpage>20</lpage><year>2011</year><pub-id pub-id-type="doi">10.3389/fnhum.2011.00039/abstract</pub-id></element-citation></ref><ref id="R32"><label>32</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Payzan-LeNestour</surname><given-names>E</given-names></name><name><surname>Bossaerts</surname><given-names>P</given-names></name></person-group><article-title>Risk, Unexpected Uncertainty, and Estimation Uncertainty: Bayesian Learning in Unstable Settings</article-title><source>PLoS Comput Biol</source><volume>7</volume><fpage>e1001048</fpage><year>2011</year><pub-id pub-id-type="pmid">21283774</pub-id></element-citation></ref><ref id="R33"><label>33</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Preuschoff</surname><given-names>K</given-names></name><name><surname>Bossaerts</surname><given-names>P</given-names></name></person-group><article-title>Adding Prediction Risk to the Theory of Reward Learning</article-title><source>Annals of the New York Academy of Sciences</source><volume>1104</volume><fpage>135</fpage><lpage>146</lpage><year>2007</year><pub-id pub-id-type="pmid">17344526</pub-id></element-citation></ref><ref id="R34"><label>34</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gold</surname><given-names>JI</given-names></name><name><surname>Law</surname><given-names>CT</given-names></name><name><surname>Connolly</surname><given-names>P</given-names></name><name><surname>Bennur</surname><given-names>S</given-names></name></person-group><article-title>The Relative Influences of Priors and Sensory Evidence on an Oculomotor Decision Variable During Perceptual Learning</article-title><source>Journal of Neurophysiology</source><volume>100</volume><fpage>2653</fpage><lpage>2668</lpage><year>2008</year><pub-id pub-id-type="pmid">18753326</pub-id></element-citation></ref><ref id="R35"><label>35</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>M</given-names></name><name><surname>Curran</surname><given-names>T</given-names></name><name><surname>Mozer</surname><given-names>MC</given-names></name><name><surname>Wilder</surname><given-names>MH</given-names></name></person-group><article-title>Sequential effects in response time reveal learning mechanisms and event representations</article-title><source>Psychological Review</source><volume>120</volume><fpage>628</fpage><lpage>666</lpage><year>2013</year><pub-id pub-id-type="pmid">23915086</pub-id></element-citation></ref><ref id="R36"><label>36</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>S</given-names></name><name><surname>Huang</surname><given-names>H</given-names></name><name><surname>Angela</surname><given-names>JY</given-names></name></person-group><article-title>Sequential effects: A Bayesian analysis of prior bias on reaction time and behavioral choice</article-title><source>CogSci</source><year>2014</year></element-citation></ref><ref id="R37"><label>37</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Gee</surname><given-names>JW</given-names></name><name><surname>Knapen</surname><given-names>T</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name></person-group><article-title>Decision-related pupil dilation reflects upcoming choice and individual bias</article-title><source>Proceedings of the National Academy of Sciences</source><volume>111</volume><fpage>E618</fpage><lpage>E625</lpage><year>2014</year></element-citation></ref><ref id="R38"><label>38</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Urai</surname><given-names>A</given-names></name><name><surname>Braun</surname><given-names>A</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name></person-group><article-title>Pupil-linked arousal is driven by decision uncertainty and alters serial choice bias</article-title><source>Nature Communications</source><comment>In press</comment></element-citation></ref><ref id="R39"><label>39</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frank</surname><given-names>MJ</given-names></name><name><surname>Badre</surname><given-names>D</given-names></name></person-group><article-title>Mechanisms of Hierarchical Reinforcement Learning in Corticostriatal Circuits 1: Computational Analysis</article-title><source>Cerebral Cortex</source><volume>22</volume><fpage>509</fpage><lpage>526</lpage><year>2012</year><pub-id pub-id-type="pmid">21693490</pub-id></element-citation></ref><ref id="R40"><label>40</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collins</surname><given-names>AGE</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name></person-group><article-title>Cognitive control over learning: creating, clustering, and generalizing task-set structure</article-title><source>Psychological Review</source><volume>120</volume><fpage>190</fpage><lpage>229</lpage><year>2013</year><pub-id pub-id-type="pmid">23356780</pub-id></element-citation></ref><ref id="R41"><label>41</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eldar</surname><given-names>E</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name><name><surname>Niv</surname><given-names>Y</given-names></name></person-group><article-title>The effects of neural gain on attention and learning</article-title><source>Nature Publishing Group</source><volume>16</volume><fpage>1146</fpage><lpage>1153</lpage><year>2013</year></element-citation></ref><ref id="R42"><label>42</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eldar</surname><given-names>E</given-names></name><name><surname>Niv</surname><given-names>Y</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><article-title>Do You See the Forest or the Tree? Neural Gain and Breadth Versus Focus in Perceptual Processing</article-title><source>Psychol Sci</source><volume>27</volume><fpage>1632</fpage><lpage>1643</lpage><year>2016</year><pub-id pub-id-type="pmid">28195019</pub-id></element-citation></ref><ref id="R43"><label>43</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Pfaff</surname><given-names>DW</given-names></name></person-group><source>Brain arousal and information theory</source><year>2006</year></element-citation></ref><ref id="R44"><label>44</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sara</surname><given-names>SJ</given-names></name><name><surname>Bouret</surname><given-names>S</given-names></name></person-group><article-title>Orienting and Reorienting: The Locus Coeruleus Mediates Cognition through Arousal</article-title><source>Neuron</source><volume>76</volume><fpage>130</fpage><lpage>141</lpage><year>2012</year><pub-id pub-id-type="pmid">23040811</pub-id></element-citation></ref><ref id="R45"><label>45</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Servan-Schreiber</surname><given-names>D</given-names></name><name><surname>Printz</surname><given-names>H</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><article-title>A network model of catecholamine effects: gain, signal-to-noise ratio, and behavior</article-title><source>Science</source><volume>249</volume><fpage>892</fpage><lpage>895</lpage><year>1990</year><pub-id pub-id-type="pmid">2392679</pub-id></element-citation></ref><ref id="R46"><label>46</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kepecs</surname><given-names>A</given-names></name><name><surname>Uchida</surname><given-names>N</given-names></name><name><surname>Zariwala</surname><given-names>HA</given-names></name><name><surname>Mainen</surname><given-names>ZF</given-names></name></person-group><article-title>Neural correlates, computation and behavioural impact of decision confidence</article-title><source>Nature</source><volume>455</volume><fpage>227</fpage><lpage>231</lpage><year>2008</year><pub-id pub-id-type="pmid">18690210</pub-id></element-citation></ref><ref id="R47"><label>47</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kiani</surname><given-names>R</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><article-title>Representation of Confidence Associated with a Decision by Neurons in the Parietal Cortex</article-title><source>Science</source><volume>324</volume><fpage>759</fpage><lpage>764</lpage><year>2009</year><pub-id pub-id-type="pmid">19423820</pub-id></element-citation></ref><ref id="R48"><label>48</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Persaud</surname><given-names>N</given-names></name><name><surname>McLeod</surname><given-names>P</given-names></name><name><surname>Cowey</surname><given-names>A</given-names></name></person-group><article-title>Post-decision wagering objectively measures awareness</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>257</fpage><lpage>261</lpage><year>2007</year><pub-id pub-id-type="pmid">17237774</pub-id></element-citation></ref><ref id="R49"><label>49</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jepma</surname><given-names>M</given-names></name><name><surname>Nieuwenhuis</surname><given-names>S</given-names></name></person-group><article-title>Pupil diameter predicts changes in the exploration-exploitation trade-off: evidence for the adaptive gain theory</article-title><source>J Cogn Neurosci</source><volume>23</volume><fpage>1587</fpage><lpage>1596</lpage><year>2011</year><pub-id pub-id-type="pmid">20666595</pub-id></element-citation></ref><ref id="R50"><label>50</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lempert</surname><given-names>KM</given-names></name><name><surname>Chen</surname><given-names>YL</given-names></name><name><surname>Fleming</surname><given-names>SM</given-names></name></person-group><article-title>Relating Pupil Dilation and Metacognitive Confidence during Auditory Decision-Making</article-title><source>PLoS ONE</source><volume>10</volume><fpage>e0126588</fpage><year>2015</year><pub-id pub-id-type="pmid">25950839</pub-id></element-citation></ref><ref id="R51"><label>51</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Satterthwaite</surname><given-names>TD</given-names></name><etal/></person-group><article-title>Dissociable but inter-related systems of cognitive control and reward during decision making: Evidence from pupillometry and event-related fMRI</article-title><source>NeuroImage</source><volume>37</volume><fpage>1017</fpage><lpage>1031</lpage><year>2007</year><pub-id pub-id-type="pmid">17632014</pub-id></element-citation></ref><ref id="R52"><label>52</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wessel</surname><given-names>JR</given-names></name><name><surname>Danielmeier</surname><given-names>C</given-names></name><name><surname>Ullsperger</surname><given-names>M</given-names></name></person-group><article-title>Error awareness revisited: accumulation of multimodal evidence from central and autonomic nervous systems</article-title><source>J Cogn Neurosci</source><volume>23</volume><fpage>3021</fpage><lpage>3036</lpage><year>2011</year><pub-id pub-id-type="pmid">21268673</pub-id></element-citation></ref><ref id="R53"><label>53</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Manohar</surname><given-names>SG</given-names></name><name><surname>Husain</surname><given-names>M</given-names></name></person-group><article-title>Reduced pupillary reward sensitivity in Parkinson&#x02019;s disease</article-title><source>npj Parkinsons Disease</source><volume>1</volume><fpage>15026</fpage><year>2015</year></element-citation></ref><ref id="R54"><label>54</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Robbins</surname><given-names>TW</given-names></name><name><surname>Everitt</surname><given-names>BJ</given-names></name></person-group><source>Arousal systems and attention</source><publisher-name>The MIT Press</publisher-name><year>1995</year></element-citation></ref><ref id="R55"><label>55</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bouret</surname><given-names>S</given-names></name><name><surname>Richmond</surname><given-names>BJ</given-names></name></person-group><article-title>Sensitivity of locus ceruleus neurons to reward value for goal-directed actions</article-title><source>Journal of Neuroscience</source><volume>35</volume><fpage>4005</fpage><lpage>4014</lpage><year>2015</year><pub-id pub-id-type="pmid">25740528</pub-id></element-citation></ref><ref id="R56"><label>56</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nieuwenhuis</surname><given-names>S</given-names></name><name><surname>De Geus</surname><given-names>EJ</given-names></name><name><surname>Aston-Jones</surname><given-names>G</given-names></name></person-group><article-title>The anatomical and functional relationship between the P3 and autonomic components of the orienting response</article-title><source>Psychophysiology</source><volume>48</volume><fpage>162</fpage><lpage>175</lpage><year>2011</year><pub-id pub-id-type="pmid">20557480</pub-id></element-citation></ref><ref id="R57"><label>57</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mather</surname><given-names>M</given-names></name><name><surname>Clewett</surname><given-names>D</given-names></name><name><surname>Sakaki</surname><given-names>M</given-names></name></person-group><article-title>Norepinephrine ignites local hot spots of neuronal excitation: How arousal amplifies selectivity in perception and memory</article-title><source>Behav Brain Sci</source><year>2015</year></element-citation></ref><ref id="R58"><label>58</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>AJ</given-names></name></person-group><article-title>change is in the eye of the beholder</article-title><source>Nature Publishing Group</source><volume>15</volume><fpage>933</fpage><lpage>935</lpage><year>2012</year></element-citation></ref><ref id="R59"><label>59</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reimer</surname><given-names>J</given-names></name><etal/></person-group><article-title>Pupil fluctuations track rapid changes in adrenergic and cholinergic activity in cortex</article-title><source>Nature Communications</source><volume>7</volume><fpage>13289</fpage><year>2016</year></element-citation></ref><ref id="R60"><label>60</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nichols</surname><given-names>TE</given-names></name><name><surname>Holmes</surname><given-names>AP</given-names></name></person-group><article-title>Nonparametric permutation tests for functional neuroimaging: a primer with examples</article-title><source>Hum Brain Mapp</source><volume>15</volume><fpage>1</fpage><lpage>25</lpage><year>2002</year><pub-id pub-id-type="pmid">11747097</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="F1" orientation="portrait" position="float"><label>Figure 1</label><caption><title>Dynamic sound-localization task</title><p>(<bold>a</bold>) Subjects listened via headphones to noise bursts with virtual source locations that varied along the frontal, azimuthal plane. The locations were sampled (points) from a Gaussian distribution (gray) with a mean that changed abruptly on unsignaled change-points (probability=0.15 for each sound) and a STD of 10&#x000b0; in low-noise blocks, 20&#x000b0; in high-noise blocks. The subjects listened passively to the sound sequence, except for occasional probe trials. All sounds except the probe sound were presented simultaneously with their corresponding locations on a semicircular arc shown on the isoluminant visual display, allowing subjects to develop priors on sound-source location based on both the auditory and visual signals and maintain a stable mapping between the two. (<bold>b</bold>) An example trial sequence showing the mean (solid line) and sampled (points) locations over 50 trials. Vertical dashed lines indicate randomly selected probe trials. (<bold>c</bold>) Probe-trial sequence. Using a mouse to control a cursor on the visual display, the subject reported: 1) the predicted location of the upcoming probe sound, followed by 250-ms fixation, presentation of the probe sound, then continued fixation for 2.5 s to allow for pupil measurements; 2) the estimated location of the probe sound; and 3) a high or low confidence report that the true location was within a small window centered on their estimate. The sound sequence then continued until the next probe. (<bold>d&#x02013;f</bold>) Schematic illustrating the changing reliability and relevance of priors for the probe sounds in <bold>a</bold> and <bold>b</bold>, as indicated. Given a fixed-width likelihood function, more reliable and relevant priors have a stronger and more beneficial influence on the percept, here represented as the posterior, which is most uncertain (widest) in <bold>e</bold> and least uncertain in <bold>f</bold>.</p></caption><graphic xlink:href="nihms865461f1"/></fig><fig id="F2" orientation="portrait" position="float"><label>Figure 2</label><caption><title>Overall prediction and estimation performance</title><p>(<bold>a</bold>&#x02013;<bold>c</bold>) Reported versus true (simulated) sound-source angle for an example subject for: (<bold>a</bold>) estimations from the control task; (<bold>b</bold>) predictions from the dynamic task (light gray points indicate change-point trials, on which the probe location was, by design, unpredictable); and (<bold>c</bold>) estimations from the dynamic task, including all trials. (<bold>d</bold>&#x02013;<bold>f</bold>) Population summaries, plotted as in (<bold>a</bold>&#x02013;<bold>c</bold>), with per-subject median values shown in black and the median of medians shown in red (<italic>n</italic>=29 subjects). For the dynamic tasks, median values were calculated in sliding 20&#x000b0; windows. Non-change-point trials were excluded from the predictions in (<bold>e</bold>). Note that the subjects&#x02019; perceptual reports (<bold>d</bold> and <bold>f</bold>) were biased slightly towards straight ahead at the far periphery. This bias, which likely reflected learned expectations that sounds were only played in the frontal plane, is accounted for in later analyses (<italic>&#x003b2;</italic><sub>5</sub> and <italic>&#x003b2;</italic><sub>6</sub> in <xref rid="FD5" ref-type="disp-formula">Eq. 5</xref>). (<bold>g</bold>&#x02013;<bold>i</bold>) STD of the perceptual errors from the dynamic task plotted versus the STD of: (<bold>g</bold>) the perceptual errors from the control task; (<bold>h</bold>) the prediction errors from the dynamic task; or (<bold>i</bold>) the expected STD of the perceptual errors, computed from the optimal, reliability-weighted combination of the control perceptual errors and the dynamic prediction errors. Points in <bold>g</bold>&#x02013;<bold>i</bold> represent data from individual subjects. Prediction and perceptual errors were computed with respect to the simulated location of the probe sound.</p></caption><graphic xlink:href="nihms865461f2"/></fig><fig id="F3" orientation="portrait" position="float"><label>Figure 3</label><caption><title>Effects of task dynamics on performance</title><p>(<bold>a</bold>) STD of the subjects&#x02019; prediction errors (filled circles) as a function of the number of sounds after a change-point (SAC) in the generative mean azimuthal location, plotted separately for the two noise conditions (colors, as indicated; generative STDs are shown as dashed lines). For comparison, prediction-error STDs are shown for an approximately optimal predictive-inference model (open diamonds). Data from change-point trials (SAC=1) are not shown because locations were, by design, unpredictable on those trials. (<bold>b</bold>) Contrast values from a linear model describing individual subject (circles) and the approximately optimal model (each diamond represents analyses based on the same sound sequence experienced by the subject connected by a line) prediction-error STD in terms of (see inset in <bold>e</bold>): 1) the difference between change-point and non-change-point trials (CP), 2,3) the linear trend from SAC 2&#x02013;6 for low-(Exp<sub>low</sub>) or high-(Exp<sub>high</sub>) noise trials, and 4) the difference between the two noise conditions (Noise). (<bold>c,d</bold>) Same conventions as in <bold>a</bold>,<bold>b</bold> but for perceptual errors on the dynamic task. Diamonds represent the theoretically predicted STD of perceptual errors computed from the optimal, precision-weighted combination of the subject- and condition-specific STDs of prior errors (circles in <bold>a</bold>, determined separately for each subject) and the subject-specific estimation-error STDs from the control task (the median value is shown as a horizontal dashed line; see <xref rid="F2" ref-type="fig">Fig. 2g</xref>). (<bold>e,f</bold>) Same conventions as in <bold>a</bold>,<bold>b</bold> but for the frequency of high-confidence reports relative to overall frequency of high-confidence reports per subject. Diamonds represent the frequency of high-confidence reports corresponding to the theoretical perceptual errors in <bold>c</bold>, computed from the fraction of the theoretical posterior distribution within the confidence window. In <bold>a</bold>,<bold>c</bold>,<bold>e</bold>, circles and error bars are mean&#x000b1;sem of values measured from all 29 subjects. In <bold>b</bold>,<bold>d</bold>,<bold>f</bold>, points are data from individual subjects. Asterisks indicate sign-rank test for <italic>H<sub>0</sub></italic>: median value from the subject data=0, <italic>p</italic>&#x0003c;0.05. In each case, paired rank-sum test for <italic>H<sub>0</sub></italic>: median difference between subject data and theoretical prediction, <italic>p</italic>&#x0003e;0.087. In all panels, only data from sequences following noticeable change-points (changes in mean of at least twice the generative STD for SAC=1) were included.</p></caption><graphic xlink:href="nihms865461f3"/></fig><fig id="F4" orientation="portrait" position="float"><label>Figure 4</label><caption><title>Effects of task dynamics on perceptual bias</title><p>(<bold>a</bold>&#x02013;<bold>c</bold>) Example data from a single subject illustrating the quantification of perceptual bias as the slope of the best-fit line to a scatter of the perceptual error versus the prediction error. Slopes close to zero reflect a low perceptual bias (i.e., the percept is unrelated to the prediction), as on change-point trials (<bold>b</bold>). Slopes closer to unity reflect a higher perceptual bias (i.e., the percept more closely matches the prediction), as on non-change-point trials (<bold>c</bold>). (<bold>d</bold>) Perceptual bias as a function of the number sounds after a change-point (SAC) in the generative mean azimuthal location, plotted separately for the two noise conditions (colors, as indicated). Circles and error bars are mean&#x000b1;sem of values measured from all 29 subjects. Diamonds indicate the theoretically predicted perceptual bias from an optimal, reliability-weighted combination of the subject- and condition-specific predictions (<xref rid="F3" ref-type="fig">Fig. 3a</xref>) and the subject-specific estimates from the control task (<xref rid="F2" ref-type="fig">Fig. 2g</xref>). (<bold>e</bold>) Contrast values from a linear model describing individual subject (circles) and model (each diamond represents analyses based on the same sound sequence experienced by the subject connected by a line) perceptual bias in terms of (see inset in <xref rid="F3" ref-type="fig">Fig. 3e</xref>): 1) the difference between change-point and non-change-point trials (CP), 2,3) the linear trend from SAC 2&#x02013;6 for low-(Exp<sub>low</sub>) or high-(Exp<sub>high</sub>) noise trials, and 4) the difference between the two noise conditions (Noise). Asterisks indicate sign-rank test for <italic>H<sub>0</sub></italic>: median value from the subject data=0, <italic>p</italic>&#x0003c;0.05. Paired rank-sum tests for <italic>H<sub>0</sub></italic>: median difference between subject data and theoretical prediction, <italic>p</italic>&#x0003c;0.01 for CP, <italic>p</italic>=0.16 for Exp<sub>low</sub>, <italic>p</italic>=0.78 for Exp<sub>high</sub>, and <italic>p</italic>&#x0003c;0.01 for Noise. In <bold>d</bold> and <bold>e</bold>, only data from sequences following noticeable change-points (changes in mean of at least twice the generative STD for SAC=1) were included.</p></caption><graphic xlink:href="nihms865461f4"/></fig><fig id="F5" orientation="portrait" position="float"><label>Figure 5</label><caption><title>Individual differences in perceptual bias</title><p>(<bold>a, b</bold>) Relationship between overall (mean) perceptual bias and either overall localization ability (STD of perceptual errors on the control task, <bold>a</bold>) or overall prediction ability (STD of prediction errors from non-change-point trials on the dynamic task, <bold>b</bold>), after accounting for the other factor (hence &#x0201c;residual&#x0201d;) via linear regression. (<bold>c</bold>&#x02013;<bold>f</bold>) The dependence of perceptual bias on various task conditions, plotted as functions of the dependence of prediction-error STD on the same conditions: <bold>c, d</bold>) the linear trend from SAC 2&#x02013;6 in the low-noise (<bold>c</bold>) and high-noise (<bold>d</bold>) condition (Exp); <bold>e</bold>) change-point versus non-change-point trials (CP); and <bold>f</bold>) high-versus low-noise condition (Noise). In each panel, points represent data from individual subjects. Lines are linear regressions. Only data from sequences following noticeable change-points (changes in mean of at least twice the generative STD for SAC=1) were included.</p></caption><graphic xlink:href="nihms865461f5"/></fig><fig id="F6" orientation="portrait" position="float"><label>Figure 6</label><caption><title>Dynamic modulation of perceptual bias by normative and non-normative factors</title><p>(<bold>a</bold>) Comparison of a parameter-free normative model (ribbons indicate mean&#x000b1;SEM simulated perceptual bias for the same task sequences experienced by the subjects) and the subjects&#x02019; behavior (points and errorbars are mean&#x000b1;SEM from 29 subjects), shown as a function of sounds after a change-point (SAC) for the two noise conditions (colors, as indicated). (<bold>b</bold>) Comparison of the linear model shown in panel <bold>e</bold> to behavior. Conventions as in panel <bold>a</bold>. (<bold>c</bold>,<bold>d</bold>) Dependence of the normative factors used in both models on task conditions: (<bold>c</bold>) prior relevance, which measures the probability of the current sound coming from the same distribution as the previous sound; and (<bold>d</bold>) prior reliability, which measures the anticipated precision of the predictive distribution relative to the likelihood distribution prior to stimulus presentation. (<bold>e</bold>) Best-fitting parameter estimates from the linear model fit to behavioral data from each subject (points) and to simulations of the parameter-free normative model (thick and thin bars indicate 95% confidence intervals over simulated subjective values and over simulated mean values across subjects, respectively). PE=prediction error. Asterisks indicate coefficients with mean values that differed from zero (t-test, <italic>p</italic>&#x0003c; 0.05).</p></caption><graphic xlink:href="nihms865461f6"/></fig><fig id="F7" orientation="portrait" position="float"><label>Figure 7</label><caption><title>Pupil diameter reflects dynamic modulations of perceptual bias within individual subjects</title><p>(<bold>a</bold>) Mean&#x000b1;sem evoked pupil response from 29 subjects, defined as the pupil diameter relative to baseline during the measurement period. Red line indicates the time of the peak mean response (1.38 sec after stimulus presentation). (<bold>b&#x02013;d</bold>) Baseline pupil diameter for trials sorted into bins according to relevance (<bold>b</bold>), reliability (<bold>c</bold>), and confidence (<bold>d</bold>). Relevance and reliability were binned in quintiles per subject, then each bin was combined across subjects. Confidence was divided into all trials with a low (0) or high (1) confidence report. Points and errorbars are mean&#x000b1;SEM from all values in each bin. (<bold>e&#x02013;g</bold>) Same as <bold>b&#x02013;d</bold>, but using the pupil diameter measured at the time of the peak response after accounting for the linear baseline dependencies. (<bold>h,i</bold>) Regression coefficients from a linear model accounting for modulation of baseline pupil diameter (<bold>h</bold>) or the evoked response (<bold>i</bold>) at each time-point using as predictors: 1) prior relevance, 2) prior reliability, 3) the upcoming confidence report, and 4) the residual perceptual bias from the linear model in <xref rid="F6" ref-type="fig">Fig. 6d</xref>. Points and error bars in <bold>h</bold> and lines and ribbons in <bold>i</bold> represent mean&#x000b1;sem of values computed per subject and thus represent within-subject modulations. Points and lines/ribbons corresponding to relevance, reliability, and confidence use the same colors as in (<bold>b</bold>&#x02013;<bold>g</bold>). Bold symbols in <bold>h</bold> and horizontal lines in <bold>i</bold> indicate periods for which <italic>H</italic><sub>0</sub>: value=0, <italic>p</italic>&#x0003c;0.05, after accounting for multiple comparisons.</p></caption><graphic xlink:href="nihms865461f7"/></fig><fig id="F8" orientation="portrait" position="float"><label>Figure 8</label><caption><title>Pupil diameter reflects individual differences in perceptual biases</title><p>(<bold>a,b</bold>) Mean baseline diameter for each subject (points) as a function of the perceptual bias (<bold>a</bold>; fits to the PE term in <xref rid="F6" ref-type="fig">Fig. 6e</xref>) and relevance-dependent bias (<bold>b</bold>; fits to the PE*relevance term in <xref rid="F6" ref-type="fig">Fig. 6e</xref>). (<bold>c,d</bold>) Mean evoked pupil response for each subject as a function of the perceptual bias (<bold>a</bold>) and relevance-dependent bias (<bold>b</bold>). Pupil responses were measured at the time of peak response (1.38 sec after stimulus presentation) and orthogonalized to subject baseline pupil measurements. (<bold>e,f</bold>) Regression coefficients describing the relationship between shared or unique variance (colors, as indicated) in PE and PE*relevance coefficients from the behavioral model and average baseline (<bold>e</bold>) or stimulus evoked (<bold>f</bold>) pupil diameter. Points and error bars in <bold>d</bold> and lines and ribbons in <bold>e</bold> represent the correlation coefficient and 95% confidence intervals of the estimate and thus represent across-subject modulations. Horizontal lines in <bold>e</bold> indicate periods for which <italic>H</italic><sub>0</sub>: value=0, <italic>p</italic>&#x0003c;0.05 after accounting for multiple comparisons.</p></caption><graphic xlink:href="nihms865461f8"/></fig></floats-group></article>